<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script>
        function copyCode(button) {
            try {
                // Encontrar o bloco de c√≥digo
                const codeBlock = button.closest('.code-block');
                const preElement = codeBlock.querySelector('pre');
                
                if (!preElement) {
                    alert('C√≥digo n√£o encontrado');
                    return;
                }
                
                // Obter o texto
                const text = preElement.textContent || preElement.innerText;
                
                // Criar elemento tempor√°rio
                const temp = document.createElement('textarea');
                temp.value = text;
                temp.style.position = 'fixed';
                temp.style.left = '-9999px';
                document.body.appendChild(temp);
                
                // Selecionar e copiar
                temp.select();
                temp.setSelectionRange(0, 99999);
                
                const success = document.execCommand('copy');
                document.body.removeChild(temp);
                
                // Feedback
                const original = button.textContent;
                if (success) {
                    button.textContent = 'Copiado!';
                    button.style.backgroundColor = '#27ae60';
                } else {
                    button.textContent = 'Erro!';
                    button.style.backgroundColor = '#e74c3c';
                }
                
                setTimeout(() => {
                    button.textContent = original;
                    button.style.backgroundColor = '#667eea';
                }, 2000);
                
            } catch (err) {
                alert('Erro ao copiar: ' + err.message);
            }
        }
    </script>
    <style>
        *{margin:0;padding:0;box-sizing:border-box}
        body{
            font-family:-apple-system,BlinkMacSystemFont,'SF Pro Display',system-ui,sans-serif;
            background:linear-gradient(135deg,#f5f7fa 0%,#c3cfe2 100%);
            min-height:100vh;padding:20px
        }
        .container{
            max-width:1200px;margin:0 auto;background:rgba(255,255,255,0.95);
            backdrop-filter:blur(20px);border-radius:24px;padding:40px;
            box-shadow:0 20px 40px rgba(25,20,20,.2);border:1px solid rgba(255,255,255,.3);
            animation:fadeInUp .8s cubic-bezier(.4,0,.2,1)
        }
        .header{text-align:center;margin-bottom:40px}
        .badge{background:linear-gradient(135deg,#667eea,#764ba2);color:#fff;padding:10px 20px;border-radius:25px;font-size:14px;font-weight:600;display:inline-block;margin-bottom:20px;box-shadow:0 4px 15px rgba(102,126,234,.3)}
        .stats-badge{background:linear-gradient(135deg,#f093fb,#f5576c);color:#fff;padding:6px 14px;border-radius:15px;font-size:12px;font-weight:600;display:inline-block;margin-bottom:15px;box-shadow:0 2px 8px rgba(240,147,251,.3)}
        .title{font-size:2.5rem;font-weight:700;color:#1a1a1a;margin-bottom:12px;background:linear-gradient(135deg,#667eea,#764ba2);-webkit-background-clip:text;-webkit-text-fill-color:transparent;background-clip:text}
        .subtitle{font-size:1.2rem;color:#666;font-weight:400;margin-bottom:30px}
        .step-container{background:rgba(255,255,255,.7);backdrop-filter:blur(10px);border-radius:16px;border-left:6px solid #667eea;padding:30px;margin-bottom:30px;box-shadow:0 8px 25px rgba(102,126,234,.1);transition:transform .3s cubic-bezier(.4,0,.2,1)}
        .step-container:hover{transform:translateY(-5px)}
        .step-header{display:flex;align-items:center;gap:15px;margin-bottom:20px}
        .step-number{background:linear-gradient(135deg,#667eea,#764ba2);color:#fff;width:45px;height:45px;border-radius:50%;display:flex;align-items:center;justify-content:center;font-weight:700;font-size:18px;flex-shrink:0;box-shadow:0 4px 15px rgba(102,126,234,.3)}
        .step-title{color:#667eea;font-size:1.5rem;font-weight:600;margin:0}
        .step-description{color:#444;line-height:1.7;font-size:1.1rem;margin-bottom:20px}
        .theory-box{background:rgba(102,126,234,.1);border:2px solid rgba(102,126,234,.3);border-radius:16px;padding:20px;margin:20px 0}
        .theory-box h4{color:#667eea;font-size:1.2rem;margin-bottom:12px;font-weight:600;display:flex;align-items:center;gap:10px}
        .code-block{background:#1e1e1e;color:#d4d4d4;padding:25px;border-radius:12px;font-family:'Monaco','Menlo','Ubuntu Mono',monospace;font-size:14px;line-height:1.6;overflow-x:auto;margin:20px 0;border-left:4px solid #667eea;position:relative}
        .code-header{background:#2d2d2d;color:#fff;padding:10px 20px;margin:-25px -25px 15px -25px;border-radius:12px 12px 0 0;font-size:12px;font-weight:600;display:flex;justify-content:space-between;align-items:center}
        .copy-btn{background:#667eea;color:#fff;border:none;padding:5px 12px;border-radius:6px;font-size:11px;cursor:pointer;transition:background .3s,transform .2s}
        .copy-btn:hover{background:#764ba2;transform:scale(1.05)}
        .output-example{background:rgba(76,175,80,.1);border:2px solid rgba(76,175,80,.3);border-radius:12px;padding:20px;margin:15px 0;font-family:monospace;font-size:13px}
        .output-header{color:#388e3c;font-weight:600;margin-bottom:10px;display:flex;align-items:center;gap:8px}
        .highlight-box{background:linear-gradient(135deg,#667eea,#764ba2);color:#fff;padding:25px;border-radius:16px;margin:25px 0;backdrop-filter:blur(10px);box-shadow:0 8px 25px rgba(102,126,234,.3)}
        .highlight-box h4{font-size:1.3rem;margin-bottom:12px;font-weight:600;display:flex;align-items:center;gap:10px}
        .warning-box{background:rgba(255,193,7,.1);border:2px solid rgba(255,193,7,.3);border-radius:16px;padding:20px;margin:20px 0}
        .warning-box h4{color:#f57c00;font-size:1.2rem;margin-bottom:12px;font-weight:600;display:flex;align-items:center;gap:10px}
        .info-panel{background:rgba(102,126,234,.1);border:2px solid rgba(102,126,234,.2);border-radius:16px;padding:20px;margin:20px 0}
        .info-panel h4{color:#667eea;font-size:1.2rem;margin-bottom:12px;font-weight:600;display:flex;align-items:center;gap:10px}
        .explanation-box{background:rgba(255,255,255,.5);border-radius:12px;padding:20px;margin:15px 0;border-left:4px solid #667eea}
        .explanation-box h5{color:#667eea;font-size:1.1rem;margin-bottom:10px;font-weight:600}
        .explanation-box p{color:#555;line-height:1.6;font-size:.95rem}
        .comparison-box{background:rgba(240,147,251,.1);border:2px solid rgba(240,147,251,.3);border-radius:16px;padding:20px;margin:20px 0}
        .comparison-box h4{color:#f093fb;font-size:1.2rem;margin-bottom:12px;font-weight:600;display:flex;align-items:center;gap:10px}
        .syntax-keyword{color:#569cd6}.syntax-string{color:#ce9178}.syntax-comment{color:#6a9955}.syntax-number{color:#b5cea8}.syntax-function{color:#dcdcaa}
        @keyframes fadeInUp{from{opacity:0;transform:translateY(30px)}to{opacity:1;transform:translateY(0)}}
        @media (max-width:768px){.container{padding:25px;margin:10px}.title{font-size:2rem}.step-container{padding:20px}.code-block{padding:15px;font-size:12px}.step-header{flex-direction:column;align-items:flex-start;gap:10px}.step-number{width:35px;height:35px;font-size:16px}.step-title{font-size:1.3rem}}
    </style>
</head>
<body>
<div class="container">
    <div class="header">
        <div class="badge">Roteiro Pr√°tico - Aula 9</div>
        <h1 class="title">Regress√£o Linear e Log√≠stica</h1>
        <p class="subtitle">M√©todos de aprendizado de m√°quina supervisionado para predi√ß√£o e classifica√ß√£o</p>
    </div>

    <div class="highlight-box">
        <h4>üéØ O que vamos aprender hoje</h4>
        <p>Exploraremos <strong>Regress√£o Linear</strong> para predi√ß√£o de valores cont√≠nuos e <strong>Regress√£o Log√≠stica</strong> para classifica√ß√£o, incluindo t√©cnicas de regulariza√ß√£o, avalia√ß√£o de modelos e interpreta√ß√£o de coeficientes para insights de neg√≥cio.</p>
    </div>

    <div class="info-panel">
        <h4>üìã Prepara√ß√£o</h4>
        <p>Abra o Google Colab e crie o notebook <strong>Aula9_Regressao_Linear_Logistica</strong>. Utilizaremos os dados musicais das aulas anteriores para implementar modelos de regress√£o e classifica√ß√£o.</p>
    </div>

    <!-- Passo 1 -->
    <div class="step-container">
        <div class="step-header">
            <div class="step-number">1</div>
            <h2 class="step-title">Configura√ß√£o e Prepara√ß√£o dos Dados</h2>
        </div>
        <div class="stats-badge">Setup & Data Prep</div>
        <p class="step-description">Configurar ambiente e preparar dados para modelos de regress√£o linear e log√≠stica.</p>

        <div class="code-block">
            <div class="code-header"><span>Instala√ß√£o e Configura√ß√£o Completa</span>                <button class="copy-btn" onclick="copyCode(this)">Copiar</button></div>
<pre><code><span class="syntax-comment"># Importar bibliotecas essenciais</span>
<span class="syntax-keyword">import</span> pandas <span class="syntax-keyword">as</span> pd
<span class="syntax-keyword">import</span> numpy <span class="syntax-keyword">as</span> np
<span class="syntax-keyword">import</span> matplotlib.pyplot <span class="syntax-keyword">as</span> plt
<span class="syntax-keyword">import</span> seaborn <span class="syntax-keyword">as</span> sns
<span class="syntax-keyword">import</span> warnings
warnings.filterwarnings(<span class="syntax-string">'ignore'</span>)

<span class="syntax-comment"># Machine Learning</span>
<span class="syntax-keyword">from</span> sklearn.model_selection <span class="syntax-keyword">import</span> train_test_split, cross_val_score, GridSearchCV
<span class="syntax-keyword">from</span> sklearn.linear_model <span class="syntax-keyword">import</span> LinearRegression, LogisticRegression
<span class="syntax-keyword">from</span> sklearn.linear_model <span class="syntax-keyword">import</span> Ridge, Lasso, ElasticNet
<span class="syntax-keyword">from</span> sklearn.preprocessing <span class="syntax-keyword">import</span> StandardScaler, PolynomialFeatures
<span class="syntax-keyword">from</span> sklearn.pipeline <span class="syntax-keyword">import</span> Pipeline

<span class="syntax-comment"># M√©tricas</span>
<span class="syntax-keyword">from</span> sklearn.metrics <span class="syntax-keyword">import</span> mean_squared_error, r2_score, mean_absolute_error
<span class="syntax-keyword">from</span> sklearn.metrics <span class="syntax-keyword">import</span> accuracy_score, classification_report, confusion_matrix
<span class="syntax-keyword">from</span> sklearn.metrics <span class="syntax-keyword">import</span> roc_curve, auc, precision_recall_curve, roc_auc_score

<span class="syntax-comment"># Estat√≠sticas</span>
<span class="syntax-keyword">from</span> scipy <span class="syntax-keyword">import</span> stats
<span class="syntax-keyword">from</span> statsmodels.stats.diagnostic <span class="syntax-keyword">import</span> het_breuschpagan
<span class="syntax-keyword">import</span> statsmodels.api <span class="syntax-keyword">as</span> sm

<span class="syntax-comment"># Configura√ß√µes de visualiza√ß√£o</span>
plt.style.use(<span class="syntax-string">'seaborn-v0_8-whitegrid'</span>)
sns.set_palette(<span class="syntax-string">"Set2"</span>)

<span class="syntax-comment"># Cores para gr√°ficos</span>
cores_regressao = {
    <span class="syntax-string">'linear'</span>: <span class="syntax-string">'#3498db'</span>,      <span class="syntax-comment"># Azul</span>
    <span class="syntax-string">'logistica'</span>: <span class="syntax-string">'#e74c3c'</span>,   <span class="syntax-comment"># Vermelho</span>
    <span class="syntax-string">'ridge'</span>: <span class="syntax-string">'#f39c12'</span>,       <span class="syntax-comment"># Laranja</span>
    <span class="syntax-string">'lasso'</span>: <span class="syntax-string">'#27ae60'</span>,       <span class="syntax-comment"># Verde</span>
    <span class="syntax-string">'elastic'</span>: <span class="syntax-string">'#9b59b6'</span>,     <span class="syntax-comment"># Roxo</span>
    <span class="syntax-string">'residuos'</span>: <span class="syntax-string">'#34495e'</span>     <span class="syntax-comment"># Cinza escuro</span>
}

np.random.seed(<span class="syntax-number">42</span>)

print(<span class="syntax-string">"üìä Ambiente configurado para Regress√£o Linear e Log√≠stica!"</span>)
print(<span class="syntax-string">"üéØ Pronto para modelagem supervisionada"</span>)</code></pre>
        </div>

        <div class="theory-box">
            <h4>üß† Aprendizado Supervisionado: Conceitos Fundamentais</h4>
            <p><strong>Aprendizado Supervisionado</strong> utiliza dados rotulados para aprender padr√µes:</p>
            <ul>
                <li><strong>Regress√£o:</strong> prediz valores cont√≠nuos (pre√ßo, vendas, temperatura)</li>
                <li><strong>Classifica√ß√£o:</strong> prediz categorias discretas (hit/n√£o hit, spam/ham)</li>
                <li><strong>Features (X):</strong> vari√°veis independentes usadas para predi√ß√£o</li>
                <li><strong>Target (y):</strong> vari√°vel dependente que queremos predizer</li>
                <li><strong>Overfitting:</strong> modelo muito complexo, memoriza treino mas falha em teste</li>
                <li><strong>Underfitting:</strong> modelo muito simples, n√£o captura padr√µes relevantes</li>
            </ul>
        </div>

        <div class="code-block">
            <div class="code-header">
                <span>Cria√ß√£o do Dataset Musical Expandido</span>
                <button class="copy-btn" onclick="copyCode(this)">Copiar</button>
            </div>
<pre><code><span class="syntax-comment"># Criar dataset musical robusto para regress√£o e classifica√ß√£o</span>
n_tracks = <span class="syntax-number">3000</span>
generos = [<span class="syntax-string">'Pop'</span>, <span class="syntax-string">'Rock'</span>, <span class="syntax-string">'Hip Hop'</span>, <span class="syntax-string">'Eletr√¥nica'</span>, <span class="syntax-string">'Indie'</span>, <span class="syntax-string">'R&B'</span>, <span class="syntax-string">'Jazz'</span>, <span class="syntax-string">'Country'</span>]
plataformas = [<span class="syntax-string">'Spotify'</span>, <span class="syntax-string">'Apple Music'</span>, <span class="syntax-string">'YouTube'</span>, <span class="syntax-string">'Deezer'</span>]

<span class="syntax-comment"># Features musicais com correla√ß√µes realistas</span>
np.random.seed(<span class="syntax-number">42</span>)

<span class="syntax-comment"># Features base</span>
energia = np.random.beta(<span class="syntax-number">2</span>, <span class="syntax-number">2</span>, n_tracks)
valencia = np.random.beta(<span class="syntax-number">2</span>, <span class="syntax-number">3</span>, n_tracks)
dancabilidade = np.random.beta(<span class="syntax-number">3</span>, <span class="syntax-number">2</span>, n_tracks)

<span class="syntax-comment"># Criar correla√ß√µes realistas</span>
<span class="syntax-comment"># Dan√ßabilidade influencia energia</span>
energia = <span class="syntax-number">0.7</span> * energia + <span class="syntax-number">0.3</span> * dancabilidade + np.random.normal(<span class="syntax-number">0</span>, <span class="syntax-number">0.1</span>, n_tracks)
energia = np.clip(energia, <span class="syntax-number">0</span>, <span class="syntax-number">1</span>)

<span class="syntax-comment"># Valencia correlaciona com energia</span>
valencia = <span class="syntax-number">0.6</span> * valencia + <span class="syntax-number">0.4</span> * energia + np.random.normal(<span class="syntax-number">0</span>, <span class="syntax-number">0.1</span>, n_tracks)
valencia = np.clip(valencia, <span class="syntax-number">0</span>, <span class="syntax-number">1</span>)

dados = {
    <span class="syntax-string">'energia'</span>: energia,
    <span class="syntax-string">'valencia'</span>: valencia,
    <span class="syntax-string">'dancabilidade'</span>: dancabilidade,
    <span class="syntax-string">'acousticness'</span>: np.random.beta(<span class="syntax-number">1</span>, <span class="syntax-number">4</span>, n_tracks),
    <span class="syntax-string">'liveness'</span>: np.random.beta(<span class="syntax-number">1</span>, <span class="syntax-number">9</span>, n_tracks),
    <span class="syntax-string">'instrumentalness'</span>: np.random.beta(<span class="syntax-number">1</span>, <span class="syntax-number">5</span>, n_tracks),
    <span class="syntax-string">'speechiness'</span>: np.random.beta(<span class="syntax-number">1</span>, <span class="syntax-number">8</span>, n_tracks),
    <span class="syntax-string">'tempo'</span>: np.random.normal(<span class="syntax-number">120</span>, <span class="syntax-number">25</span>, n_tracks),
    <span class="syntax-string">'duracao_minutos'</span>: np.random.lognormal(mean=<span class="syntax-number">1.1</span>, sigma=<span class="syntax-number">0.4</span>, size=n_tracks),
    <span class="syntax-string">'ano_lancamento'</span>: np.random.choice(<span class="syntax-function">range</span>(<span class="syntax-number">1990</span>, <span class="syntax-number">2025</span>), n_tracks),
    <span class="syntax-string">'genero'</span>: np.random.choice(generos, size=n_tracks),
    <span class="syntax-string">'plataforma_principal'</span>: np.random.choice(plataformas, size=n_tracks)
}

df = pd.DataFrame(dados)

<span class="syntax-comment"># Clipping e ajustes</span>
df[<span class="syntax-string">'tempo'</span>] = np.clip(df[<span class="syntax-string">'tempo'</span>], <span class="syntax-number">60</span>, <span class="syntax-number">200</span>)
df[<span class="syntax-string">'duracao_minutos'</span>] = np.clip(df[<span class="syntax-string">'duracao_minutos'</span>], <span class="syntax-number">1</span>, <span class="syntax-number">8</span>)

<span class="syntax-comment"># Vari√°veis derivadas</span>
df[<span class="syntax-string">'idade_musica'</span>] = <span class="syntax-number">2024</span> - df[<span class="syntax-string">'ano_lancamento'</span>]
df[<span class="syntax-string">'e_musica_nova'</span>] = (df[<span class="syntax-string">'idade_musica'</span>] <= <span class="syntax-number">2</span>).astype(int)
df[<span class="syntax-string">'e_dancante'</span>] = (df[<span class="syntax-string">'dancabilidade'</span>] > <span class="syntax-number">0.7</span>).astype(int)

<span class="syntax-comment"># TARGET VARIABLES</span>

<span class="syntax-comment"># 1. REGRESS√ÉO: Popularidade (0-100) baseada em features</span>
<span class="syntax-comment"># Modelo linear com ru√≠do</span>
popularidade = (
    <span class="syntax-number">20</span> +                                    <span class="syntax-comment"># baseline</span>
    <span class="syntax-number">25</span> * df[<span class="syntax-string">'energia'</span>] +                      <span class="syntax-comment"># energia aumenta popularidade</span>
    <span class="syntax-number">20</span> * df[<span class="syntax-string">'valencia'</span>] +                     <span class="syntax-comment"># val√™ncia positiva</span>
    <span class="syntax-number">15</span> * df[<span class="syntax-string">'dancabilidade'</span>] +                <span class="syntax-comment"># dan√ßabilidade</span>
    -<span class="syntax-number">10</span> * df[<span class="syntax-string">'acousticness'</span>] +                <span class="syntax-comment"># menos ac√∫stico = mais pop</span>
    <span class="syntax-number">5</span> * df[<span class="syntax-string">'e_musica_nova'</span>] +                 <span class="syntax-comment"># m√∫sica nova tem boost</span>
    (df[<span class="syntax-string">'genero'</span>] == <span class="syntax-string">'Pop'</span>).astype(int) * <span class="syntax-number">8</span> +  <span class="syntax-comment"># Pop tem vantagem</span>
    np.random.normal(<span class="syntax-number">0</span>, <span class="syntax-number">8</span>, n_tracks)            <span class="syntax-comment"># ru√≠do aleat√≥rio</span>
)
df[<span class="syntax-string">'popularidade'</span>] = np.clip(popularidade, <span class="syntax-number">0</span>, <span class="syntax-number">100</span>)

<span class="syntax-comment"># 2. REGRESS√ÉO: Streams (milh√µes)</span>
log_streams = (
    <span class="syntax-number">1.5</span> +                                    <span class="syntax-comment"># baseline em log</span>
    <span class="syntax-number">1.2</span> * df[<span class="syntax-string">'popularidade'</span>] / <span class="syntax-number">100</span> +           <span class="syntax-comment"># popularidade ‚Üí streams</span>
    <span class="syntax-number">0.8</span> * df[<span class="syntax-string">'dancabilidade'</span>] +                <span class="syntax-comment"># dan√ß√°vel = mais streams</span>
    <span class="syntax-number">0.5</span> * df[<span class="syntax-string">'energia'</span>] +                      <span class="syntax-comment"># energia</span>
    -<span class="syntax-number">0.3</span> * df[<span class="syntax-string">'idade_musica'</span>] / <span class="syntax-number">10</span> +          <span class="syntax-comment"># m√∫sicas antigas t√™m menos streams</span>
    np.random.normal(<span class="syntax-number">0</span>, <span class="syntax-number">0.4</span>, n_tracks)          <span class="syntax-comment"># ru√≠do</span>
)
df[<span class="syntax-string">'streams_milhoes'</span>] = np.exp(log_streams)

<span class="syntax-comment"># 3. CLASSIFICA√á√ÉO: Hit (1) ou N√£o Hit (0)</span>
<span class="syntax-comment"># Baseado em popularidade com threshold probabil√≠stico</span>
prob_hit = <span class="syntax-number">1</span> / (<span class="syntax-number">1</span> + np.exp(-(<span class="syntax-number">0.15</span> * (df[<span class="syntax-string">'popularidade'</span>] - <span class="syntax-number">50</span>))))  <span class="syntax-comment"># log√≠stica</span>
df[<span class="syntax-string">'hit'</span>] = np.random.binomial(<span class="syntax-number">1</span>, prob_hit, n_tracks)

<span class="syntax-comment"># 4. CLASSIFICA√á√ÉO MULTICLASSE: Categoria de sucesso</span>
<span class="syntax-keyword">def</span> <span class="syntax-function">categorizar_sucesso</span>(pop):
    if pop >= <span class="syntax-number">75</span>: return <span class="syntax-string">'Mega Hit'</span>
    elif pop >= <span class="syntax-number">60</span>: return <span class="syntax-string">'Hit'</span>
    elif pop >= <span class="syntax-number">40</span>: return <span class="syntax-string">'Moderado'</span>
    else: return <span class="syntax-string">'Baixo'</span>

df[<span class="syntax-string">'categoria_sucesso'</span>] = df[<span class="syntax-string">'popularidade'</span>].apply(categorizar_sucesso)

<span class="syntax-comment"># Encoding de vari√°veis categ√≥ricas</span>
df_encoded = pd.get_dummies(df, columns=[<span class="syntax-string">'genero'</span>, <span class="syntax-string">'plataforma_principal'</span>], prefix=[<span class="syntax-string">'genero'</span>, <span class="syntax-string">'plat'</span>])

<span class="syntax-comment"># Preparar features para modelagem</span>
numeric_features = [<span class="syntax-string">'energia'</span>, <span class="syntax-string">'valencia'</span>, <span class="syntax-string">'dancabilidade'</span>, <span class="syntax-string">'acousticness'</span>,
                   <span class="syntax-string">'liveness'</span>, <span class="syntax-string">'instrumentalness'</span>, <span class="syntax-string">'speechiness'</span>, <span class="syntax-string">'tempo'</span>,
                   <span class="syntax-string">'duracao_minutos'</span>, <span class="syntax-string">'idade_musica'</span>, <span class="syntax-string">'e_musica_nova'</span>, <span class="syntax-string">'e_dancante'</span>]

categorical_features = [col for col in df_encoded.columns if col.startswith((<span class="syntax-string">'genero_'</span>, <span class="syntax-string">'plat_'</span>))]
all_features = numeric_features + categorical_features

print(<span class="syntax-string">f"üìä Dataset criado: {df.shape[0]:,} m√∫sicas"</span>)
print(<span class="syntax-string">f"üéµ Features num√©ricas: {len(numeric_features)}"</span>)
print(<span class="syntax-string">f"üè∑Ô∏è Features categ√≥ricas: {len(categorical_features)}"</span>)
print(<span class="syntax-string">f"üéØ Hits no dataset: {df['hit'].sum():,} ({df['hit'].mean()*100:.1f}%)"</span>)
print(<span class="syntax-string">f"üìà Popularidade m√©dia: {df['popularidade'].mean():.1f}"</span>)
print(<span class="syntax-string">f"üéß Streams m√©dios: {df['streams_milhoes'].mean():.1f}M"</span>)

<span class="syntax-comment"># Visualiza√ß√£o inicial dos dados</span>
fig, axes = plt.subplots(<span class="syntax-number">2</span>, <span class="syntax-number">2</span>, figsize=(<span class="syntax-number">15</span>, <span class="syntax-number">10</span>))
fig.suptitle(<span class="syntax-string">'An√°lise Explorat√≥ria - Targets para Regress√£o e Classifica√ß√£o'</span>, fontsize=<span class="syntax-number">16</span>)

<span class="syntax-comment"># Distribui√ß√£o da popularidade</span>
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].hist(df[<span class="syntax-string">'popularidade'</span>], bins=<span class="syntax-number">30</span>, color=cores_regressao[<span class="syntax-string">'linear'</span>], alpha=<span class="syntax-number">0.7</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_title(<span class="syntax-string">'Distribui√ß√£o da Popularidade'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_xlabel(<span class="syntax-string">'Popularidade'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_ylabel(<span class="syntax-string">'Frequ√™ncia'</span>)

<span class="syntax-comment"># Distribui√ß√£o dos streams (log scale)</span>
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].hist(np.log(df[<span class="syntax-string">'streams_milhoes'</span>]), bins=<span class="syntax-number">30</span>, color=cores_regressao[<span class="syntax-string">'ridge'</span>], alpha=<span class="syntax-number">0.7</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_title(<span class="syntax-string">'Distribui√ß√£o dos Streams (log)'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_xlabel(<span class="syntax-string">'Log(Streams)'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_ylabel(<span class="syntax-string">'Frequ√™ncia'</span>)

<span class="syntax-comment"># Hits vs N√£o Hits</span>
hit_counts = df[<span class="syntax-string">'hit'</span>].value_counts()
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].bar([<span class="syntax-string">'N√£o Hit'</span>, <span class="syntax-string">'Hit'</span>], hit_counts, 
                   color=[cores_regressao[<span class="syntax-string">'residuos'</span>], cores_regressao[<span class="syntax-string">'logistica'</span>]])
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_title(<span class="syntax-string">'Distribui√ß√£o de Hits'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_ylabel(<span class="syntax-string">'Quantidade'</span>)

<span class="syntax-comment"># Categorias de sucesso</span>
cat_counts = df[<span class="syntax-string">'categoria_sucesso'</span>].value_counts()
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].bar(cat_counts.index, cat_counts.values, 
                   color=[cores_regressao[<span class="syntax-string">'lasso'</span>], cores_regressao[<span class="syntax-string">'elastic'</span>], 
                          cores_regressao[<span class="syntax-string">'linear'</span>], cores_regressao[<span class="syntax-string">'ridge'</span>]])
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].set_title(<span class="syntax-string">'Categorias de Sucesso'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].set_ylabel(<span class="syntax-string">'Quantidade'</span>)
plt.setp(axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].get_xticklabels(), rotation=<span class="syntax-number">45</span>)

plt.tight_layout()
plt.show()</code></pre>
        </div>
    </div>

    <!-- Passo 2 -->
    <div class="step-container">
        <div class="step-header">
            <div class="step-number">2</div>
            <h2 class="step-title">Regress√£o Linear - Teoria e Implementa√ß√£o</h2>
        </div>
        <div class="stats-badge">Linear Regression</div>
        <p class="step-description">Implementar e analisar modelos de regress√£o linear simples e m√∫ltipla.</p>

        <div class="theory-box">
            <h4>üìä Regress√£o Linear: Fundamentos Matem√°ticos</h4>
            <p><strong>Regress√£o Linear</strong> modela a rela√ß√£o entre vari√°vel dependente e independentes:</p>
            <ul>
                <li><strong>Simples:</strong> y = Œ≤‚ÇÄ + Œ≤‚ÇÅx + Œµ (uma feature)</li>
                <li><strong>M√∫ltipla:</strong> y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çöx‚Çö + Œµ</li>
                <li><strong>Premissas:</strong> linearidade, independ√™ncia, homocedasticidade, normalidade dos res√≠duos</li>
                <li><strong>M√©todo dos M√≠nimos Quadrados:</strong> minimiza soma dos quadrados dos res√≠duos</li>
                <li><strong>R¬≤:</strong> propor√ß√£o da vari√¢ncia explicada pelo modelo (0-1)</li>
            </ul>
        </div>

        <div class="code-block">
            <div class="code-header">
                <span>Regress√£o Linear Simples e M√∫ltipla</span>
                <button class="copy-btn" onclick="copyCode(this)">Copiar</button>
            </div>
<pre><code><span class="syntax-comment"># REGRESS√ÉO LINEAR SIMPLES: Energia vs Popularidade</span>
print(<span class="syntax-string">"üéØ REGRESS√ÉO LINEAR SIMPLES"</span>)
print(<span class="syntax-string">"="*50</span>)

X_simple = df[[<span class="syntax-string">'energia'</span>]]
y_pop = df[<span class="syntax-string">'popularidade'</span>]

<span class="syntax-comment"># Split dos dados</span>
X_train_simple, X_test_simple, y_train_pop, y_test_pop = train_test_split(
    X_simple, y_pop, test_size=<span class="syntax-number">0.2</span>, random_state=<span class="syntax-number">42</span>
)

<span class="syntax-comment"># Treinar modelo</span>
modelo_simples = LinearRegression()
modelo_simples.fit(X_train_simple, y_train_pop)

<span class="syntax-comment"># Predi√ß√µes</span>
y_pred_simple = modelo_simples.predict(X_test_simple)

<span class="syntax-comment"># M√©tricas</span>
r2_simple = r2_score(y_test_pop, y_pred_simple)
rmse_simple = np.sqrt(mean_squared_error(y_test_pop, y_pred_simple))
mae_simple = mean_absolute_error(y_test_pop, y_pred_simple)

print(<span class="syntax-string">f"üìä Coeficiente (Œ≤‚ÇÅ): {modelo_simples.coef_[0]:.3f}"</span>)
print(<span class="syntax-string">f"üìä Intercepto (Œ≤‚ÇÄ): {modelo_simples.intercept_:.3f}"</span>)
print(<span class="syntax-string">f"üìä Equa√ß√£o: Popularidade = {modelo_simples.intercept_:.2f} + {modelo_simples.coef_[0]:.2f} √ó Energia"</span>)
print(<span class="syntax-string">f"üìà R¬≤: {r2_simple:.3f}"</span>)
print(<span class="syntax-string">f"üìà RMSE: {rmse_simple:.3f}"</span>)
print(<span class="syntax-string">f"üìà MAE: {mae_simple:.3f}"</span>)

<span class="syntax-comment"># REGRESS√ÉO LINEAR M√öLTIPLA</span>
print(<span class="syntax-string">f"\nüéØ REGRESS√ÉO LINEAR M√öLTIPLA"</span>)
print(<span class="syntax-string">"="*50</span>)

<span class="syntax-comment"># Selecionar features mais relevantes</span>
X_multiple = df_encoded[numeric_features]
X_train_mult, X_test_mult, y_train_mult, y_test_mult = train_test_split(
    X_multiple, y_pop, test_size=<span class="syntax-number">0.2</span>, random_state=<span class="syntax-number">42</span>
)

<span class="syntax-comment"># Padronizar features (importante para interpreta√ß√£o)</span>
scaler = StandardScaler()
X_train_mult_scaled = scaler.fit_transform(X_train_mult)
X_test_mult_scaled = scaler.transform(X_test_mult)

<span class="syntax-comment"># Treinar modelo m√∫ltiplo</span>
modelo_multiplo = LinearRegression()
modelo_multiplo.fit(X_train_mult_scaled, y_train_mult)

<span class="syntax-comment"># Predi√ß√µes</span>
y_pred_mult = modelo_multiplo.predict(X_test_mult_scaled)

<span class="syntax-comment"># M√©tricas</span>
r2_mult = r2_score(y_test_mult, y_pred_mult)
rmse_mult = np.sqrt(mean_squared_error(y_test_mult, y_pred_mult))
mae_mult = mean_absolute_error(y_test_mult, y_pred_mult)

print(<span class="syntax-string">f"üìà R¬≤: {r2_mult:.3f}"</span>)
print(<span class="syntax-string">f"üìà RMSE: {rmse_mult:.3f}"</span>)
print(<span class="syntax-string">f"üìà MAE: {mae_mult:.3f}"</span>)
print(<span class="syntax-string">f"üìà Melhoria no R¬≤: {((r2_mult - r2_simple) / r2_simple * 100):.1f}%"</span>)

<span class="syntax-comment"># An√°lise de coeficientes</span>
coef_df = pd.DataFrame({
    <span class="syntax-string">'Feature'</span>: numeric_features,
    <span class="syntax-string">'Coeficiente'</span>: modelo_multiplo.coef_,
    <span class="syntax-string">'Coef_Abs'</span>: np.abs(modelo_multiplo.coef_)
}).sort_values(<span class="syntax-string">'Coef_Abs'</span>, ascending=<span class="syntax-keyword">False</span>)

print(<span class="syntax-string">f"\nüîç IMPORT√ÇNCIA DAS FEATURES (Coeficientes Padronizados):"</span>)
for _, row in coef_df.head(<span class="syntax-number">5</span>).iterrows():
    print(<span class="syntax-string">f"  {row['Feature']:20s}: {row['Coeficiente']:7.3f}"</span>)

<span class="syntax-comment"># VISUALIZA√á√ïES</span>
fig, axes = plt.subplots(<span class="syntax-number">2</span>, <span class="syntax-number">3</span>, figsize=(<span class="syntax-number">18</span>, <span class="syntax-number">12</span>))
fig.suptitle(<span class="syntax-string">'An√°lise de Regress√£o Linear - Popularidade Musical'</span>, fontsize=<span class="syntax-number">16</span>)

<span class="syntax-comment"># 1. Scatter plot simples</span>
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].scatter(X_test_simple, y_test_pop, alpha=<span class="syntax-number">0.6</span>, color=cores_regressao[<span class="syntax-string">'linear'</span>])
x_range = np.linspace(X_test_simple.min(), X_test_simple.max(), <span class="syntax-number">100</span>).reshape(-<span class="syntax-number">1</span>, <span class="syntax-number">1</span>)
y_range_pred = modelo_simples.predict(x_range)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].plot(x_range, y_range_pred, color=cores_regressao[<span class="syntax-string">'logistica'</span>], linewidth=<span class="syntax-number">2</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_xlabel(<span class="syntax-string">'Energia'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_ylabel(<span class="syntax-string">'Popularidade'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_title(<span class="syntax-string">f'Regress√£o Simples (R¬≤={r2_simple:.3f})'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 2. Predito vs Real (simples)</span>
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].scatter(y_test_pop, y_pred_simple, alpha=<span class="syntax-number">0.6</span>, color=cores_regressao[<span class="syntax-string">'linear'</span>])
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].plot([y_test_pop.min(), y_test_pop.max()], [y_test_pop.min(), y_test_pop.max()], 
                      <span class="syntax-string">'r--'</span>, linewidth=<span class="syntax-number">2</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_xlabel(<span class="syntax-string">'Popularidade Real'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_ylabel(<span class="syntax-string">'Popularidade Predita'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_title(<span class="syntax-string">'Predito vs Real (Simples)'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 3. Predito vs Real (m√∫ltipla)</span>
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].scatter(y_test_mult, y_pred_mult, alpha=<span class="syntax-number">0.6</span>, color=cores_regressao[<span class="syntax-string">'ridge'</span>])
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].plot([y_test_mult.min(), y_test_mult.max()], [y_test_mult.min(), y_test_mult.max()], 
                      <span class="syntax-string">'r--'</span>, linewidth=<span class="syntax-number">2</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].set_xlabel(<span class="syntax-string">'Popularidade Real'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].set_ylabel(<span class="syntax-string">'Popularidade Predita'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].set_title(<span class="syntax-string">f'Predito vs Real (M√∫ltipla, R¬≤={r2_mult:.3f})'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 4. Res√≠duos vs Predito</span>
residuos = y_test_mult - y_pred_mult
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].scatter(y_pred_mult, residuos, alpha=<span class="syntax-number">0.6</span>, color=cores_regressao[<span class="syntax-string">'residuos'</span>])
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].axhline(y=<span class="syntax-number">0</span>, color=<span class="syntax-string">'red'</span>, linestyle=<span class="syntax-string">'--'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_xlabel(<span class="syntax-string">'Valores Preditos'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_ylabel(<span class="syntax-string">'Res√≠duos'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_title(<span class="syntax-string">'An√°lise de Res√≠duos'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 5. Q-Q plot dos res√≠duos</span>
stats.probplot(residuos, dist=<span class="syntax-string">"norm"</span>, plot=axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>])
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].set_title(<span class="syntax-string">'Q-Q Plot - Normalidade dos Res√≠duos'</span>)
<span class="syntax-comment"># 6. Cross-validation scores distribution</span>
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].boxplot([cv_scores_reg, cv_scores_class], 
                         labels=[<span class="syntax-string">'Regress√£o R¬≤'</span>, <span class="syntax-string">'Log√≠stica AUC'</span>])
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_ylabel(<span class="syntax-string">'Score'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_title(<span class="syntax-string">'Distribui√ß√£o dos Scores CV'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 7. Learning curves (simplified)</span>
ax7 = axes[<span class="syntax-number">2</span>, <span class="syntax-number">0</span>]
train_sizes = [<span class="syntax-number">0.1</span>, <span class="syntax-number">0.3</span>, <span class="syntax-number">0.5</span>, <span class="syntax-number">0.7</span>, <span class="syntax-number">0.9</span>]
train_scores_reg = []
val_scores_reg = []

for size in train_sizes:
    n_samples = int(size * <span class="syntax-function">len</span>(X_train_mult_scaled))
    X_subset = X_train_mult_scaled[:n_samples]
    y_subset = y_train_mult[:n_samples]
    
    <span class="syntax-comment"># Score de treino</span>
    modelo_temp = LinearRegression()
    modelo_temp.fit(X_subset, y_subset)
    train_score = modelo_temp.score(X_subset, y_subset)
    val_score = modelo_temp.score(X_test_mult_scaled, y_test_mult)
    
    train_scores_reg.append(train_score)
    val_scores_reg.append(val_score)

ax7.plot(train_sizes, train_scores_reg, <span class="syntax-string">'o-'</span>, color=cores_regressao[<span class="syntax-string">'linear'</span>], label=<span class="syntax-string">'Treino'</span>)
ax7.plot(train_sizes, val_scores_reg, <span class="syntax-string">'o-'</span>, color=cores_regressao[<span class="syntax-string">'logistica'</span>], label=<span class="syntax-string">'Valida√ß√£o'</span>)
ax7.set_xlabel(<span class="syntax-string">'Tamanho do Conjunto de Treino'</span>)
ax7.set_ylabel(<span class="syntax-string">'R¬≤ Score'</span>)
ax7.set_title(<span class="syntax-string">'Learning Curve - Regress√£o'</span>)
ax7.legend()
ax7.grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 8. Feature importance correlation</span>
ax8 = axes[<span class="syntax-number">2</span>, <span class="syntax-number">1</span>]

<span class="syntax-comment"># Comparar import√¢ncia linear vs log√≠stica</span>
linear_importance = np.abs(modelo_multiplo.coef_)
logistic_importance = np.abs(logistic_simple.coef_[<span class="syntax-number">0</span>])

<span class="syntax-comment"># Normalizar para compara√ß√£o</span>
linear_norm = linear_importance / linear_importance.max()
logistic_norm = logistic_importance / logistic_importance.max()

ax8.scatter(linear_norm, logistic_norm, alpha=<span class="syntax-number">0.7</span>, s=<span class="syntax-number">60</span>, color=cores_regressao[<span class="syntax-string">'elastic'</span>])
ax8.plot([<span class="syntax-number">0</span>, <span class="syntax-number">1</span>], [<span class="syntax-number">0</span>, <span class="syntax-number">1</span>], <span class="syntax-string">'k--'</span>, alpha=<span class="syntax-number">0.5</span>)
ax8.set_xlabel(<span class="syntax-string">'Import√¢ncia Linear (normalizada)'</span>)
ax8.set_ylabel(<span class="syntax-string">'Import√¢ncia Log√≠stica (normalizada)'</span>)
ax8.set_title(<span class="syntax-string">'Correla√ß√£o de Import√¢ncias'</span>)
ax8.grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 9. Prediction intervals</span>
ax9 = axes[<span class="syntax-number">2</span>, <span class="syntax-number">2</span>]

<span class="syntax-comment"># Residual standard error</span>
residual_se = np.sqrt(np.mean(residuos_diag**<span class="syntax-number">2</span>))
prediction_interval = <span class="syntax-number">1.96</span> * residual_se  <span class="syntax-comment"># 95% CI</span>

<span class="syntax-comment"># Plot prediction bands</span>
sorted_idx = np.argsort(y_pred_diag)
y_pred_sorted = y_pred_diag[sorted_idx]
y_test_sorted = y_test_mult.iloc[sorted_idx]

ax9.scatter(y_pred_diag, y_test_mult, alpha=<span class="syntax-number">0.6</span>, color=cores_regressao[<span class="syntax-string">'linear'</span>])
ax9.plot([y_test_mult.min(), y_test_mult.max()], [y_test_mult.min(), y_test_mult.max()], 
         <span class="syntax-string">'r-'</span>, linewidth=<span class="syntax-number">2</span>, label=<span class="syntax-string">'Perfeito'</span>)

<span class="syntax-comment"># Prediction bands</span>
ax9.fill_between(y_pred_sorted, 
                 y_pred_sorted - prediction_interval, 
                 y_pred_sorted + prediction_interval, 
                 alpha=<span class="syntax-number">0.2</span>, color=cores_regressao[<span class="syntax-string">'ridge'</span>], 
                 label=<span class="syntax-string">'IC 95%'</span>)

ax9.set_xlabel(<span class="syntax-string">'Predi√ß√µes'</span>)
ax9.set_ylabel(<span class="syntax-string">'Valores Reais'</span>)
ax9.set_title(<span class="syntax-string">'Intervalos de Predi√ß√£o'</span>)
ax9.legend()
ax9.grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

plt.tight_layout()
plt.show()

<span class="syntax-comment"># RELAT√ìRIO FINAL DE DIAGN√ìSTICOS</span>
print(<span class="syntax-string">f"\nüìã RELAT√ìRIO FINAL DE DIAGN√ìSTICOS"</span>)
print(<span class="syntax-string">"="*60</span>)

print(<span class="syntax-string">f"üîç REGRESS√ÉO LINEAR:"</span>)
print(<span class="syntax-string">f"   ‚Ä¢ R¬≤ Teste: {r2_mult:.3f}"</span>)
print(<span class="syntax-string">f"   ‚Ä¢ RMSE: {rmse_mult:.3f}"</span>)
print(<span class="syntax-string">f"   ‚Ä¢ Cross-val R¬≤: {cv_scores_reg.mean():.3f} ¬± {cv_scores_reg.std():.3f}"</span>)
print(<span class="syntax-string">f"   ‚Ä¢ Normalidade res√≠duos: {'‚úÖ' if p_jb > 0.05 else '‚ùå'} (p={p_jb:.3f})"</span>)
print(<span class="syntax-string">f"   ‚Ä¢ Outliers: {len(outliers_idx)} ({len(outliers_idx)/len(residuos_diag)*100:.1f}%)"</span>)

print(<span class="syntax-string">f"\nüéØ REGRESS√ÉO LOG√çSTICA:"</span>)
print(<span class="syntax-string">f"   ‚Ä¢ ROC-AUC: {roc_auc:.3f}"</span>)
print(<span class="syntax-string">f"   ‚Ä¢ Acur√°cia: {accuracy:.3f}"</span>)
print(<span class="syntax-string">f"   ‚Ä¢ Cross-val AUC: {cv_scores_class.mean():.3f} ¬± {cv_scores_class.std():.3f}"</span>)
print(<span class="syntax-string">f"   ‚Ä¢ Calibra√ß√£o H-L: {'‚úÖ' if hl_p > 0.05 else '‚ùå'} (p={hl_p:.3f})"</span>)

print(<span class="syntax-string">f"\nüí° RECOMENDA√á√ïES:"</span>)
if r2_mult < <span class="syntax-number">0.7</span>:
    print(<span class="syntax-string">f"   ‚Ä¢ Considerar features adicionais ou transforma√ß√µes"</span>)
if p_jb <= <span class="syntax-number">0.05</span>:
    print(<span class="syntax-string">f"   ‚Ä¢ Res√≠duos n√£o-normais: considerar transforma√ß√µes"</span>)
if <span class="syntax-function">len</span>(outliers_idx) > <span class="syntax-function">len</span>(residuos_diag) * <span class="syntax-number">0.05</span>:
    print(<span class="syntax-string">f"   ‚Ä¢ Muitos outliers: investigar e possivelmente remover"</span>)
if roc_auc < <span class="syntax-number">0.8</span>:
    print(<span class="syntax-string">f"   ‚Ä¢ Performance log√≠stica moderada: mais features ou algoritmos"</span>)
if hl_p <= <span class="syntax-number">0.05</span>:
    print(<span class="syntax-string">f"   ‚Ä¢ Modelo mal calibrado: considerar calibra√ß√£o"</span>)

print(<span class="syntax-string">f"\n‚úÖ Diagn√≥sticos completos! Modelos validados e prontos para uso."</span>)

<span class="syntax-comment"># 6. Import√¢ncia das features</span>
top_features = coef_df.head(<span class="syntax-number">8</span>)
colors = [cores_regressao[<span class="syntax-string">'lasso'</span>] if x > <span class="syntax-number">0</span> else cores_regressao[<span class="syntax-string">'elastic'</span>] for x in top_features[<span class="syntax-string">'Coeficiente'</span>]]
bars = axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].barh(top_features[<span class="syntax-string">'Feature'</span>], top_features[<span class="syntax-string">'Coeficiente'</span>], color=colors)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].axvline(x=<span class="syntax-number">0</span>, color=<span class="syntax-string">'black'</span>, linestyle=<span class="syntax-string">'-'</span>, alpha=<span class="syntax-number">0.3</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_xlabel(<span class="syntax-string">'Coeficiente Padronizado'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_title(<span class="syntax-string">'Import√¢ncia das Features'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

plt.tight_layout()
plt.show()</code></pre>
        </div>

        <div class="explanation-box">
            <h5>üìà Interpretando os Resultados da Regress√£o Linear</h5>
            <ul>
                <li><strong>R¬≤:</strong> porcentagem da varia√ß√£o em y explicada pelo modelo</li>
                <li><strong>RMSE:</strong> erro m√©dio em unidades da vari√°vel dependente</li>
                <li><strong>Coeficientes:</strong> mudan√ßa em y para cada unidade de x</li>
                <li><strong>Res√≠duos:</strong> devem ser aleat√≥rios (sem padr√µes) e normalmente distribu√≠dos</li>
                <li><strong>Homocedasticidade:</strong> vari√¢ncia constante dos res√≠duos</li>
            </ul>
        </div>
    </div>

    <!-- Passo 3 -->
    <div class="step-container">
        <div class="step-header">
            <div class="step-number">3</div>
            <h2 class="step-title">Regulariza√ß√£o - Ridge, Lasso e Elastic Net</h2>
        </div>
        <div class="stats-badge">Regularization</div>
        <p class="step-description">Implementar t√©cnicas de regulariza√ß√£o para combater overfitting e sele√ß√£o de features.</p>

        <div class="theory-box">
            <h4>üéØ Regulariza√ß√£o: Controlando Complexidade do Modelo</h4>
            <p><strong>Regulariza√ß√£o</strong> adiciona penalidade √† fun√ß√£o de custo para evitar overfitting:</p>
            <ul>
                <li><strong>Ridge (L2):</strong> penaliza a soma dos quadrados dos coeficientes</li>
                <li><strong>Lasso (L1):</strong> penaliza a soma dos valores absolutos (sele√ß√£o autom√°tica)</li>
                <li><strong>Elastic Net:</strong> combina L1 + L2, balanceando sele√ß√£o e redu√ß√£o</li>
                <li><strong>Hiperpar√¢metro Œ±:</strong> controla for√ßa da regulariza√ß√£o</li>
                <li><strong>Cross-validation:</strong> usado para encontrar Œ± √≥timo</li>
            </ul>
        </div>

        <div class="code-block">
            <div class="code-header">
                <span>Modelos Regularizados</span>
                <button class="copy-btn" onclick="copyCode(this)">Copiar</button>
            </div>
<pre><code><span class="syntax-comment"># PREPARA√á√ÉO PARA REGULARIZA√á√ÉO</span>
print(<span class="syntax-string">"üéØ COMPARA√á√ÉO DE T√âCNICAS DE REGULARIZA√á√ÉO"</span>)
print(<span class="syntax-string">"="*60</span>)

<span class="syntax-comment"># Usar dataset com mais features (incluindo categ√≥ricas)</span>
X_full = df_encoded[all_features]
y_target = df[<span class="syntax-string">'popularidade'</span>]

<span class="syntax-comment"># Split</span>
X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(
    X_full, y_target, test_size=<span class="syntax-number">0.2</span>, random_state=<span class="syntax-number">42</span>
)

<span class="syntax-comment"># Padroniza√ß√£o (crucial para regulariza√ß√£o)</span>
scaler_full = StandardScaler()
X_train_scaled = scaler_full.fit_transform(X_train_full)
X_test_scaled = scaler_full.transform(X_test_full)

<span class="syntax-comment"># Definir range de alphas para testar</span>
alphas = np.logspace(-<span class="syntax-number">4</span>, <span class="syntax-number">2</span>, <span class="syntax-number">50</span>)  <span class="syntax-comment"># 0.0001 to 100</span>

<span class="syntax-comment"># RIDGE REGRESSION</span>
print(<span class="syntax-string">"üîµ Testando Ridge Regression..."</span>)
ridge_scores = []
ridge_coefs = []

for alpha in alphas:
    ridge = Ridge(alpha=alpha)
    <span class="syntax-comment"># Cross-validation</span>
    scores = cross_val_score(ridge, X_train_scaled, y_train_full, cv=<span class="syntax-number">5</span>, scoring=<span class="syntax-string">'r2'</span>)
    ridge_scores.append(scores.mean())
    
    <span class="syntax-comment"># Treinar para obter coeficientes</span>
    ridge.fit(X_train_scaled, y_train_full)
    ridge_coefs.append(ridge.coef_.copy())

<span class="syntax-comment"># Melhor alpha para Ridge</span>
best_alpha_ridge = alphas[np.argmax(ridge_scores)]
ridge_best = Ridge(alpha=best_alpha_ridge)
ridge_best.fit(X_train_scaled, y_train_full)
ridge_pred = ridge_best.predict(X_test_scaled)
ridge_r2 = r2_score(y_test_full, ridge_pred)

print(<span class="syntax-string">f"  Melhor Œ±: {best_alpha_ridge:.4f}"</span>)
print(<span class="syntax-string">f"  R¬≤ no teste: {ridge_r2:.3f}"</span>)

<span class="syntax-comment"># LASSO REGRESSION</span>
print(<span class="syntax-string">"üü¢ Testando Lasso Regression..."</span>)
lasso_scores = []
lasso_coefs = []
lasso_n_features = []

for alpha in alphas:
    lasso = Lasso(alpha=alpha, max_iter=<span class="syntax-number">1000</span>)
    <span class="syntax-comment"># Cross-validation</span>
    scores = cross_val_score(lasso, X_train_scaled, y_train_full, cv=<span class="syntax-number">5</span>, scoring=<span class="syntax-string">'r2'</span>)
    lasso_scores.append(scores.mean())
    
    <span class="syntax-comment"># Treinar para obter coeficientes</span>
    lasso.fit(X_train_scaled, y_train_full)
    lasso_coefs.append(lasso.coef_.copy())
    lasso_n_features.append(np.sum(lasso.coef_ != <span class="syntax-number">0</span>))

<span class="syntax-comment"># Melhor alpha para Lasso</span>
best_alpha_lasso = alphas[np.argmax(lasso_scores)]
lasso_best = Lasso(alpha=best_alpha_lasso, max_iter=<span class="syntax-number">1000</span>)
lasso_best.fit(X_train_scaled, y_train_full)
lasso_pred = lasso_best.predict(X_test_scaled)
lasso_r2 = r2_score(y_test_full, lasso_pred)

print(<span class="syntax-string">f"  Melhor Œ±: {best_alpha_lasso:.4f}"</span>)
print(<span class="syntax-string">f"  R¬≤ no teste: {lasso_r2:.3f}"</span>)
print(<span class="syntax-string">f"  Features selecionadas: {np.sum(lasso_best.coef_ != 0)}/{len(all_features)}"</span>)

<span class="syntax-comment"># ELASTIC NET</span>
print(<span class="syntax-string">"üü£ Testando Elastic Net..."</span>)
<span class="syntax-comment"># Grid search para alpha e l1_ratio</span>
param_grid = {
    <span class="syntax-string">'alpha'</span>: alphas[::5],  <span class="syntax-comment"># Subconjunto para velocidade</span>
    <span class="syntax-string">'l1_ratio'</span>: [<span class="syntax-number">0.1</span>, <span class="syntax-number">0.3</span>, <span class="syntax-number">0.5</span>, <span class="syntax-number">0.7</span>, <span class="syntax-number">0.9</span>]
}

elastic = ElasticNet(max_iter=<span class="syntax-number">1000</span>)
grid_search = GridSearchCV(elastic, param_grid, cv=<span class="syntax-number">5</span>, scoring=<span class="syntax-string">'r2'</span>, n_jobs=-<span class="syntax-number">1</span>)
grid_search.fit(X_train_scaled, y_train_full)

elastic_best = grid_search.best_estimator_
elastic_pred = elastic_best.predict(X_test_scaled)
elastic_r2 = r2_score(y_test_full, elastic_pred)

print(<span class="syntax-string">f"  Melhor Œ±: {grid_search.best_params_['alpha']:.4f}"</span>)
print(<span class="syntax-string">f"  Melhor l1_ratio: {grid_search.best_params_['l1_ratio']:.1f}"</span>)
print(<span class="syntax-string">f"  R¬≤ no teste: {elastic_r2:.3f}"</span>)
print(<span class="syntax-string">f"  Features selecionadas: {np.sum(elastic_best.coef_ != 0)}/{len(all_features)}"</span>)

<span class="syntax-comment"># MODELO LINEAR BASELINE (sem regulariza√ß√£o)</span>
linear_baseline = LinearRegression()
linear_baseline.fit(X_train_scaled, y_train_full)
linear_pred = linear_baseline.predict(X_test_scaled)
linear_r2 = r2_score(y_test_full, linear_pred)

print(<span class="syntax-string">f"\nüìä RESUMO COMPARATIVO:"</span>)
print(<span class="syntax-string">f"  Linear Simples: R¬≤ = {linear_r2:.3f}"</span>)
print(<span class="syntax-string">f"  Ridge:         R¬≤ = {ridge_r2:.3f}"</span>)
print(<span class="syntax-string">f"  Lasso:         R¬≤ = {lasso_r2:.3f}"</span>)
print(<span class="syntax-string">f"  Elastic Net:   R¬≤ = {elastic_r2:.3f}"</span>)

<span class="syntax-comment"># VISUALIZA√á√ïES COMPARATIVAS</span>
fig, axes = plt.subplots(<span class="syntax-number">2</span>, <span class="syntax-number">3</span>, figsize=(<span class="syntax-number">18</span>, <span class="syntax-number">12</span>))
fig.suptitle(<span class="syntax-string">'An√°lise de Regulariza√ß√£o - Compara√ß√£o de M√©todos'</span>, fontsize=<span class="syntax-number">16</span>)

<span class="syntax-comment"># 1. Curvas de valida√ß√£o - Ridge</span>
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].semilogx(alphas, ridge_scores, <span class="syntax-string">'b-'</span>, linewidth=<span class="syntax-number">2</span>, color=cores_regressao[<span class="syntax-string">'ridge'</span>])
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].axvline(best_alpha_ridge, color=<span class="syntax-string">'red'</span>, linestyle=<span class="syntax-string">'--'</span>, 
                           label=<span class="syntax-string">f'Melhor Œ± = {best_alpha_ridge:.4f}'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_xlabel(<span class="syntax-string">'Alpha'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_ylabel(<span class="syntax-string">'R¬≤ (CV)'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_title(<span class="syntax-string">'Ridge - Curva de Valida√ß√£o'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].legend()
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 2. Curvas de valida√ß√£o - Lasso</span>
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].semilogx(alphas, lasso_scores, <span class="syntax-string">'g-'</span>, linewidth=<span class="syntax-number">2</span>, color=cores_regressao[<span class="syntax-string">'lasso'</span>])
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].axvline(best_alpha_lasso, color=<span class="syntax-string">'red'</span>, linestyle=<span class="syntax-string">'--'</span>, 
                           label=<span class="syntax-string">f'Melhor Œ± = {best_alpha_lasso:.4f}'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_xlabel(<span class="syntax-string">'Alpha'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_ylabel(<span class="syntax-string">'R¬≤ (CV)'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_title(<span class="syntax-string">'Lasso - Curva de Valida√ß√£o'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].legend()
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 3. N√∫mero de features vs Alpha (Lasso)</span>
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].semilogx(alphas, lasso_n_features, <span class="syntax-string">'g-'</span>, linewidth=<span class="syntax-number">2</span>, color=cores_regressao[<span class="syntax-string">'lasso'</span>])
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].axvline(best_alpha_lasso, color=<span class="syntax-string">'red'</span>, linestyle=<span class="syntax-string">'--'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].set_xlabel(<span class="syntax-string">'Alpha'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].set_ylabel(<span class="syntax-string">'N√∫mero de Features'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].set_title(<span class="syntax-string">'Lasso - Sele√ß√£o de Features'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 4. Compara√ß√£o de coeficientes</span>
feature_comparison = pd.DataFrame({
    <span class="syntax-string">'Feature'</span>: all_features,
    <span class="syntax-string">'Linear'</span>: linear_baseline.coef_,
    <span class="syntax-string">'Ridge'</span>: ridge_best.coef_,
    <span class="syntax-string">'Lasso'</span>: lasso_best.coef_,
    <span class="syntax-string">'ElasticNet'</span>: elastic_best.coef_
})

<span class="syntax-comment"># Top 10 features mais importantes no Lasso</span>
top_lasso_features = feature_comparison[feature_comparison[<span class="syntax-string">'Lasso'</span>] != <span class="syntax-number">0</span>].head(<span class="syntax-number">10</span>)

x_pos = np.arange(<span class="syntax-function">len</span>(top_lasso_features))
width = <span class="syntax-number">0.2</span>

axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].bar(x_pos - <span class="syntax-number">1.5</span>*width, top_lasso_features[<span class="syntax-string">'Linear'</span>], width, 
                     label=<span class="syntax-string">'Linear'</span>, color=cores_regressao[<span class="syntax-string">'linear'</span>], alpha=<span class="syntax-number">0.8</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].bar(x_pos - <span class="syntax-number">0.5</span>*width, top_lasso_features[<span class="syntax-string">'Ridge'</span>], width, 
                     label=<span class="syntax-string">'Ridge'</span>, color=cores_regressao[<span class="syntax-string">'ridge'</span>], alpha=<span class="syntax-number">0.8</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].bar(x_pos + <span class="syntax-number">0.5</span>*width, top_lasso_features[<span class="syntax-string">'Lasso'</span>], width, 
                     label=<span class="syntax-string">'Lasso'</span>, color=cores_regressao[<span class="syntax-string">'lasso'</span>], alpha=<span class="syntax-number">0.8</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].bar(x_pos + <span class="syntax-number">1.5</span>*width, top_lasso_features[<span class="syntax-string">'ElasticNet'</span>], width, 
                     label=<span class="syntax-string">'Elastic'</span>, color=cores_regressao[<span class="syntax-string">'elastic'</span>], alpha=<span class="syntax-number">0.8</span>)

axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_xlabel(<span class="syntax-string">'Features'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_ylabel(<span class="syntax-string">'Coeficiente'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_title(<span class="syntax-string">'Compara√ß√£o de Coeficientes'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_xticks(x_pos)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_xticklabels(top_lasso_features[<span class="syntax-string">'Feature'</span>], rotation=<span class="syntax-number">45</span>, ha=<span class="syntax-string">'right'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].legend()
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 5. Compara√ß√£o de performance</span>
models = [<span class="syntax-string">'Linear'</span>, <span class="syntax-string">'Ridge'</span>, <span class="syntax-string">'Lasso'</span>, <span class="syntax-string">'Elastic Net'</span>]
r2_scores = [linear_r2, ridge_r2, lasso_r2, elastic_r2]
colors = [cores_regressao[<span class="syntax-string">'linear'</span>], cores_regressao[<span class="syntax-string">'ridge'</span>], 
          cores_regressao[<span class="syntax-string">'lasso'</span>], cores_regressao[<span class="syntax-string">'elastic'</span>]]

bars = axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].bar(models, r2_scores, color=colors, alpha=<span class="syntax-number">0.8</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].set_ylabel(<span class="syntax-string">'R¬≤ Score'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].set_title(<span class="syntax-string">'Compara√ß√£o de Performance'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].set_ylim(<span class="syntax-number">0</span>, max(r2_scores) * <span class="syntax-number">1.1</span>)

<span class="syntax-comment"># Adicionar valores nas barras</span>
for bar, score in <span class="syntax-function">zip</span>(bars, r2_scores):
    axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].text(bar.get_x() + bar.get_width()/<span class="syntax-number">2</span>, bar.get_height() + <span class="syntax-number">0.01</span>, 
                             <span class="syntax-string">f'{score:.3f}'</span>, ha=<span class="syntax-string">'center'</span>, va=<span class="syntax-string">'bottom'</span>, fontweight=<span class="syntax-string">'bold'</span>)

axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 6. Path de coeficientes (Lasso)</span>
ridge_coefs_array = np.array(ridge_coefs)
for i in <span class="syntax-function">range</span>(min(<span class="syntax-number">10</span>, ridge_coefs_array.shape[<span class="syntax-number">1</span>])):  <span class="syntax-comment"># Top 10 features</span>
    axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].semilogx(alphas, ridge_coefs_array[:, i], alpha=<span class="syntax-number">0.7</span>)

axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].axvline(best_alpha_ridge, color=<span class="syntax-string">'red'</span>, linestyle=<span class="syntax-string">'--'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_xlabel(<span class="syntax-string">'Alpha'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_ylabel(<span class="syntax-string">'Coeficientes'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_title(<span class="syntax-string">'Ridge - Path dos Coeficientes'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

plt.tight_layout()
plt.show()</code></pre>
        </div>
    </div>

    <!-- Passo 4 -->
    <div class="step-container">
        <div class="step-header">
            <div class="step-number">4</div>
            <h2 class="step-title">Regress√£o Log√≠stica - Classifica√ß√£o</h2>
        </div>
        <div class="stats-badge">Logistic Regression</div>
        <p class="step-description">Implementar regress√£o log√≠stica para classifica√ß√£o bin√°ria e multiclasse.</p>

        <div class="theory-box">
            <h4>üéØ Regress√£o Log√≠stica: Classifica√ß√£o Probabil√≠stica</h4>
            <p><strong>Regress√£o Log√≠stica</strong> modela probabilidades usando fun√ß√£o log√≠stica:</p>
            <ul>
                <li><strong>Fun√ß√£o Sigmoid:</strong> p = 1/(1 + e^(-z)), onde z = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + ... + Œ≤‚Çöx‚Çö</li>
                <li><strong>Log-odds:</strong> ln(p/(1-p)) = z (rela√ß√£o linear com features)</li>
                <li><strong>Maximum Likelihood:</strong> estima par√¢metros maximizando verossimilhan√ßa</li>
                <li><strong>Regulariza√ß√£o:</strong> L1 (sele√ß√£o) e L2 (redu√ß√£o) tamb√©m aplic√°veis</li>
                <li><strong>Multiclasse:</strong> One-vs-Rest ou Multinomial</li>
            </ul>
        </div>

        <div class="code-block">
            <div class="code-header">
                <span>Regress√£o Log√≠stica Bin√°ria e Multiclasse</span>
                <button class="copy-btn" onclick="copyCode(this)">Copiar</button>
            </div>
<pre><code><span class="syntax-comment"># REGRESS√ÉO LOG√çSTICA BIN√ÅRIA: Hit vs N√£o Hit</span>
print(<span class="syntax-string">"üéØ REGRESS√ÉO LOG√çSTICA BIN√ÅRIA"</span>)
print(<span class="syntax-string">"="*50</span>)

<span class="syntax-comment"># Preparar dados para classifica√ß√£o bin√°ria</span>
X_class = df_encoded[numeric_features]  <span class="syntax-comment"># Usar s√≥ features num√©ricas para simplicidade</span>
y_class = df[<span class="syntax-string">'hit'</span>]

<span class="syntax-comment"># Split</span>
X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(
    X_class, y_class, test_size=<span class="syntax-number">0.2</span>, random_state=<span class="syntax-number">42</span>, stratify=y_class
)

<span class="syntax-comment"># Padronizar</span>
scaler_class = StandardScaler()
X_train_class_scaled = scaler_class.fit_transform(X_train_class)
X_test_class_scaled = scaler_class.transform(X_test_class)

<span class="syntax-comment"># 1. LOG√çSTICA SIMPLES</span>
print(<span class="syntax-string">"üìä Modelo Log√≠stico B√°sico..."</span>)
logistic_simple = LogisticRegression(random_state=<span class="syntax-number">42</span>, max_iter=<span class="syntax-number">1000</span>)
logistic_simple.fit(X_train_class_scaled, y_train_class)

<span class="syntax-comment"># Predi√ß√µes</span>
y_pred_class = logistic_simple.predict(X_test_class_scaled)
y_proba_class = logistic_simple.predict_proba(X_test_class_scaled)[:, <span class="syntax-number">1</span>]

<span class="syntax-comment"># M√©tricas</span>
accuracy = accuracy_score(y_test_class, y_pred_class)
roc_auc = roc_auc_score(y_test_class, y_proba_class)

print(<span class="syntax-string">f"  Acur√°cia: {accuracy:.3f}"</span>)
print(<span class="syntax-string">f"  ROC-AUC: {roc_auc:.3f}"</span>)

<span class="syntax-comment"># Coeficientes (log-odds)</span>
coef_logistic = pd.DataFrame({
    <span class="syntax-string">'Feature'</span>: numeric_features,
    <span class="syntax-string">'Coeficiente'</span>: logistic_simple.coef_[<span class="syntax-number">0</span>],
    <span class="syntax-string">'Odds_Ratio'</span>: np.exp(logistic_simple.coef_[<span class="syntax-number">0</span>])
}).sort_values(<span class="syntax-string">'Coeficiente'</span>, key=<span class="syntax-keyword">lambda</span> x: np.abs(x), ascending=<span class="syntax-keyword">False</span>)

print(<span class="syntax-string">f"\nüîç TOP 5 FEATURES MAIS IMPORTANTES:"</span>)
for _, row in coef_logistic.head(<span class="syntax-number">5</span>).iterrows():
    print(<span class="syntax-string">f"  {row['Feature']:20s}: coef={row['Coeficiente']:7.3f}, OR={row['Odds_Ratio']:6.3f}"</span>)

<span class="syntax-comment"># 2. LOG√çSTICA COM REGULARIZA√á√ÉO</span>
print(<span class="syntax-string">f"\nüìä Comparando Regulariza√ß√£o L1 vs L2..."</span>)

<span class="syntax-comment"># Log√≠stica com L1 (Lasso)</span>
logistic_l1 = LogisticRegression(penalty=<span class="syntax-string">'l1'</span>, solver=<span class="syntax-string">'liblinear'</span>, C=<span class="syntax-number">1.0</span>, random_state=<span class="syntax-number">42</span>)
logistic_l1.fit(X_train_class_scaled, y_train_class)
y_proba_l1 = logistic_l1.predict_proba(X_test_class_scaled)[:, <span class="syntax-number">1</span>]
roc_auc_l1 = roc_auc_score(y_test_class, y_proba_l1)

<span class="syntax-comment"># Log√≠stica com L2 (Ridge)</span>
logistic_l2 = LogisticRegression(penalty=<span class="syntax-string">'l2'</span>, C=<span class="syntax-number">1.0</span>, random_state=<span class="syntax-number">42</span>, max_iter=<span class="syntax-number">1000</span>)
logistic_l2.fit(X_train_class_scaled, y_train_class)
y_proba_l2 = logistic_l2.predict_proba(X_test_class_scaled)[:, <span class="syntax-number">1</span>]
roc_auc_l2 = roc_auc_score(y_test_class, y_proba_l2)

print(<span class="syntax-string">f"  ROC-AUC L1: {roc_auc_l1:.3f} (features: {np.sum(logistic_l1.coef_[0] != 0)})"</span>)
print(<span class="syntax-string">f"  ROC-AUC L2: {roc_auc_l2:.3f}"</span>)

<span class="syntax-comment"># 3. REGRESS√ÉO LOG√çSTICA MULTICLASSE</span>
print(<span class="syntax-string">f"\nüéØ REGRESS√ÉO LOG√çSTICA MULTICLASSE"</span>)
print(<span class="syntax-string">"="*50</span>)

<span class="syntax-comment"># Preparar dados multiclasse</span>
y_multi = df[<span class="syntax-string">'categoria_sucesso'</span>]
X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(
    X_class, y_multi, test_size=<span class="syntax-number">0.2</span>, random_state=<span class="syntax-number">42</span>, stratify=y_multi
)

<span class="syntax-comment"># Padronizar</span>
X_train_multi_scaled = scaler_class.fit_transform(X_train_multi)
X_test_multi_scaled = scaler_class.transform(X_test_multi)

<span class="syntax-comment"># Modelo multiclasse</span>
logistic_multi = LogisticRegression(multi_class=<span class="syntax-string">'multinomial'</span>, solver=<span class="syntax-string">'lbfgs'</span>, 
                                   max_iter=<span class="syntax-number">1000</span>, random_state=<span class="syntax-number">42</span>)
logistic_multi.fit(X_train_multi_scaled, y_train_multi)

<span class="syntax-comment"># Predi√ß√µes</span>
y_pred_multi = logistic_multi.predict(X_test_multi_scaled)
y_proba_multi = logistic_multi.predict_proba(X_test_multi_scaled)

<span class="syntax-comment"># M√©tricas</span>
accuracy_multi = accuracy_score(y_test_multi, y_pred_multi)
print(<span class="syntax-string">f"üìä Acur√°cia Multiclasse: {accuracy_multi:.3f}"</span>)

<span class="syntax-comment"># VISUALIZA√á√ïES</span>
fig, axes = plt.subplots(<span class="syntax-number">2</span>, <span class="syntax-number">3</span>, figsize=(<span class="syntax-number">18</span>, <span class="syntax-number">12</span>))
fig.suptitle(<span class="syntax-string">'An√°lise de Regress√£o Log√≠stica - Classifica√ß√£o Musical'</span>, fontsize=<span class="syntax-number">16</span>)

<span class="syntax-comment"># 1. Distribui√ß√£o de probabilidades</span>
hit_probs = y_proba_class[y_test_class == <span class="syntax-number">1</span>]
no_hit_probs = y_proba_class[y_test_class == <span class="syntax-number">0</span>]

axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].hist(no_hit_probs, bins=<span class="syntax-number">30</span>, alpha=<span class="syntax-number">0.7</span>, label=<span class="syntax-string">'N√£o Hit'</span>, 
                    color=cores_regressao[<span class="syntax-string">'residuos'</span>], density=<span class="syntax-keyword">True</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].hist(hit_probs, bins=<span class="syntax-number">30</span>, alpha=<span class="syntax-number">0.7</span>, label=<span class="syntax-string">'Hit'</span>, 
                    color=cores_regressao[<span class="syntax-string">'logistica'</span>], density=<span class="syntax-keyword">True</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].axvline(<span class="syntax-number">0.5</span>, color=<span class="syntax-string">'black'</span>, linestyle=<span class="syntax-string">'--'</span>, label=<span class="syntax-string">'Threshold 0.5'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_xlabel(<span class="syntax-string">'Probabilidade Predita'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_ylabel(<span class="syntax-string">'Densidade'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_title(<span class="syntax-string">'Distribui√ß√£o de Probabilidades'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].legend()
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 2. Curva ROC</span>
fpr, tpr, _ = roc_curve(y_test_class, y_proba_class)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].plot(fpr, tpr, linewidth=<span class="syntax-number">2</span>, color=cores_regressao[<span class="syntax-string">'logistica'</span>], 
                    label=<span class="syntax-string">f'ROC (AUC = {roc_auc:.3f})'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].plot([<span class="syntax-number">0</span>, <span class="syntax-number">1</span>], [<span class="syntax-number">0</span>, <span class="syntax-number">1</span>], <span class="syntax-string">'k--'</span>, linewidth=<span class="syntax-number">1</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_xlabel(<span class="syntax-string">'Taxa de Falsos Positivos'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_ylabel(<span class="syntax-string">'Taxa de Verdadeiros Positivos'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_title(<span class="syntax-string">'Curva ROC'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].legend()
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 3. Coeficientes (Odds Ratios)</span>
top_coefs = coef_logistic.head(<span class="syntax-number">8</span>)
colors = [cores_regressao[<span class="syntax-string">'lasso'</span>] if x > <span class="syntax-number">0</span> else cores_regressao[<span class="syntax-string">'elastic'</span>] 
          for x in top_coefs[<span class="syntax-string">'Coeficiente'</span>]]

bars = axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].barh(top_coefs[<span class="syntax-string">'Feature'</span>], top_coefs[<span class="syntax-string">'Odds_Ratio'</span>], color=colors)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].axvline(x=<span class="syntax-number">1</span>, color=<span class="syntax-string">'black'</span>, linestyle=<span class="syntax-string">'-'</span>, alpha=<span class="syntax-number">0.3</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].set_xlabel(<span class="syntax-string">'Odds Ratio'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].set_title(<span class="syntax-string">'Import√¢ncia das Features (OR)'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 4. Matriz de Confus√£o</span>
<span class="syntax-keyword">from</span> sklearn.metrics <span class="syntax-keyword">import</span> ConfusionMatrixDisplay
cm = confusion_matrix(y_test_class, y_pred_class)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[<span class="syntax-string">'N√£o Hit'</span>, <span class="syntax-string">'Hit'</span>])
disp.plot(ax=axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>], cmap=<span class="syntax-string">'Blues'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_title(<span class="syntax-string">'Matriz de Confus√£o'</span>)

<span class="syntax-comment"># 5. Compara√ß√£o L1 vs L2</span>
models_reg = [<span class="syntax-string">'Sem Reg.'</span>, <span class="syntax-string">'L1 (Lasso)'</span>, <span class="syntax-string">'L2 (Ridge)'</span>]
aucs_reg = [roc_auc, roc_auc_l1, roc_auc_l2]
colors_reg = [cores_regressao[<span class="syntax-string">'linear'</span>], cores_regressao[<span class="syntax-string">'lasso'</span>], cores_regressao[<span class="syntax-string">'ridge'</span>]]

bars = axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].bar(models_reg, aucs_reg, color=colors_reg, alpha=<span class="syntax-number">0.8</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].set_ylabel(<span class="syntax-string">'ROC-AUC'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].set_title(<span class="syntax-string">'Compara√ß√£o Regulariza√ß√£o'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].set_ylim(<span class="syntax-number">0</span>, <span class="syntax-number">1</span>)

for bar, auc_val in <span class="syntax-function">zip</span>(bars, aucs_reg):
    axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].text(bar.get_x() + bar.get_width()/<span class="syntax-number">2</span>, bar.get_height() + <span class="syntax-number">0.02</span>, 
                             <span class="syntax-string">f'{auc_val:.3f}'</span>, ha=<span class="syntax-string">'center'</span>, va=<span class="syntax-string">'bottom'</span>, fontweight=<span class="syntax-string">'bold'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 6. Matriz de Confus√£o Multiclasse</span>
cm_multi = confusion_matrix(y_test_multi, y_pred_multi)
<span class="syntax-keyword">import</span> itertools

classes = logistic_multi.classes_
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].imshow(cm_multi, interpolation=<span class="syntax-string">'nearest'</span>, cmap=<span class="syntax-string">'Blues'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_title(<span class="syntax-string">'Matriz Confus√£o Multiclasse'</span>)

tick_marks = np.arange(<span class="syntax-function">len</span>(classes))
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_xticks(tick_marks)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_yticks(tick_marks)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_xticklabels(classes, rotation=<span class="syntax-number">45</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_yticklabels(classes)

<span class="syntax-comment"># Adicionar texto na matriz</span>
thresh = cm_multi.max() / <span class="syntax-number">2</span>.
for i, j in itertools.product(<span class="syntax-function">range</span>(cm_multi.shape[<span class="syntax-number">0</span>]), <span class="syntax-function">range</span>(cm_multi.shape[<span class="syntax-number">1</span>])):
    axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].text(j, i, <span class="syntax-function">format</span>(cm_multi[i, j], <span class="syntax-string">'d'</span>),
                        horizontalalignment=<span class="syntax-string">"center"</span>,
                        color=<span class="syntax-string">"white"</span> if cm_multi[i, j] > thresh else <span class="syntax-string">"black"</span>)

axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_ylabel(<span class="syntax-string">'Classe Real'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">2</span>].set_xlabel(<span class="syntax-string">'Classe Predita'</span>)

plt.tight_layout()
plt.show()

<span class="syntax-comment"># RELAT√ìRIO DETALHADO</span>
print(<span class="syntax-string">f"\nüìã RELAT√ìRIO DETALHADO - CLASSIFICA√á√ÉO"</span>)
print(<span class="syntax-string">"="*60</span>)
print(classification_report(y_test_class, y_pred_class))

print(<span class="syntax-string">f"\nüìã RELAT√ìRIO MULTICLASSE"</span>)
print(<span class="syntax-string">"="*60</span>)
print(classification_report(y_test_multi, y_pred_multi))</code></pre>
        </div>

        <div class="explanation-box">
            <h5>üéØ Interpretando Odds Ratios</h5>
            <ul>
                <li><strong>OR = 1:</strong> a feature n√£o afeta as chances (neutro)</li>
                <li><strong>OR > 1:</strong> aumenta as chances da classe positiva</li>
                <li><strong>OR < 1:</strong> diminui as chances da classe positiva</li>
                <li><strong>OR = 2:</strong> dobra as chances; OR = 0.5 reduz pela metade</li>
                <li><strong>Coeficiente positivo:</strong> OR > 1; negativo: OR < 1</li>
            </ul>
        </div>
    </div>

    <!-- Passo 5 -->
    <div class="step-container">
        <div class="step-header">
            <div class="step-number">5</div>
            <h2 class="step-title">Diagn√≥sticos de Modelo e Valida√ß√£o</h2>
        </div>
        <div class="stats-badge">Model Diagnostics</div>
        <p class="step-description">Realizar diagn√≥sticos abrangentes para validar premissas e qualidade dos modelos.</p>

        <div class="code-block">
            <div class="code-header">
                <span>Diagn√≥sticos Completos de Modelos</span>
                <button class="copy-btn" onclick="copyCode(this)">Copiar</button>
            </div>
<pre><code><span class="syntax-comment"># DIAGN√ìSTICOS PARA REGRESS√ÉO LINEAR</span>
print(<span class="syntax-string">"üîç DIAGN√ìSTICOS DE REGRESS√ÉO LINEAR"</span>)
print(<span class="syntax-string">"="*50</span>)

<span class="syntax-comment"># Usar modelo m√∫ltiplo j√° treinado</span>
y_pred_diag = modelo_multiplo.predict(X_test_mult_scaled)
residuos_diag = y_test_mult - y_pred_diag

<span class="syntax-comment"># 1. TESTE DE NORMALIDADE DOS RES√çDUOS</span>
<span class="syntax-keyword">from</span> scipy.stats <span class="syntax-keyword">import</span> shapiro, jarque_bera, anderson

<span class="syntax-comment"># Shapiro-Wilk (para amostras menores)</span>
if <span class="syntax-function">len</span>(residuos_diag) <= <span class="syntax-number">5000</span>:
    stat_shapiro, p_shapiro = shapiro(residuos_diag)
    print(<span class="syntax-string">f"üìä Teste Shapiro-Wilk: W = {stat_shapiro:.4f}, p-value = {p_shapiro:.4f}"</span>)
    print(<span class="syntax-string">f"   {'‚úÖ' if p_shapiro > 0.05 else '‚ùå'} Normalidade (Œ± = 0.05)"</span>)

<span class="syntax-comment"># Jarque-Bera</span>
stat_jb, p_jb = jarque_bera(residuos_diag)
print(<span class="syntax-string">f"üìä Teste Jarque-Bera: JB = {stat_jb:.4f}, p-value = {p_jb:.4f}"</span>)
print(<span class="syntax-string">f"   {'‚úÖ' if p_jb > 0.05 else '‚ùå'} Normalidade (Œ± = 0.05)"</span>)

<span class="syntax-comment"># 2. TESTE DE HOMOCEDASTICIDADE</span>
<span class="syntax-comment"># Breusch-Pagan test</span>
<span class="syntax-keyword">try</span>:
    <span class="syntax-comment"># Reconstruir para statsmodels</span>
    X_with_const = sm.add_constant(X_test_mult_scaled)
    stat_bp, p_bp, _, _ = het_breuschpagan(residuos_diag, X_with_const)
    print(<span class="syntax-string">f"üìä Teste Breusch-Pagan: LM = {stat_bp:.4f}, p-value = {p_bp:.4f}"</span>)
    print(<span class="syntax-string">f"   {'‚úÖ' if p_bp > 0.05 else '‚ùå'} Homocedasticidade (Œ± = 0.05)"</span>)
<span class="syntax-keyword">except</span>:
    print(<span class="syntax-string">"üìä Teste Breusch-Pagan: n√£o foi poss√≠vel calcular"</span>)

<span class="syntax-comment"># 3. TESTE DE AUTOCORRELA√á√ÉO DOS RES√çDUOS</span>
<span class="syntax-keyword">from</span> statsmodels.stats.diagnostic <span class="syntax-keyword">import</span> acorr_ljungbox

<span class="syntax-comment"># Ljung-Box test</span>
ljung_result = acorr_ljungbox(residuos_diag, lags=<span class="syntax-number">10</span>, return_df=<span class="syntax-keyword">True</span>)
p_ljung = ljung_result[<span class="syntax-string">'lb_pvalue'</span>].iloc[-<span class="syntax-number">1</span>]  <span class="syntax-comment"># √∫ltimo lag</span>
print(<span class="syntax-string">f"üìä Teste Ljung-Box: p-value = {p_ljung:.4f}"</span>)
print(<span class="syntax-string">f"   {'‚úÖ' if p_ljung > 0.05 else '‚ùå'} Independ√™ncia (Œ± = 0.05)"</span>)

<span class="syntax-comment"># 4. DETEC√á√ÉO DE OUTLIERS</span>
<span class="syntax-comment"># Res√≠duos padronizados</span>
residuos_std = residuos_diag / residuos_diag.std()
outliers_idx = np.where(np.abs(residuos_std) > <span class="syntax-number">3</span>)[<span class="syntax-number">0</span>]
print(<span class="syntax-string">f"üìä Outliers (|z| > 3): {len(outliers_idx)} de {len(residuos_diag)} ({len(outliers_idx)/len(residuos_diag)*100:.1f}%)"</span>)

<span class="syntax-comment"># 5. DIAGN√ìSTICOS PARA REGRESS√ÉO LOG√çSTICA</span>
print(<span class="syntax-string">f"\nüîç DIAGN√ìSTICOS DE REGRESS√ÉO LOG√çSTICA"</span>)
print(<span class="syntax-string">"="*50</span>)

<span class="syntax-comment"># Res√≠duos de Pearson para log√≠stica</span>
y_proba_diag = logistic_simple.predict_proba(X_test_class_scaled)[:, <span class="syntax-number">1</span>]
residuos_pearson = (y_test_class - y_proba_diag) / np.sqrt(y_proba_diag * (<span class="syntax-number">1</span> - y_proba_diag))

<span class="syntax-comment"># Deviance residuals</span>
y_pred_class_diag = logistic_simple.predict(X_test_class_scaled)
residuos_deviance = np.sqrt(-<span class="syntax-number">2</span> * (y_test_class * np.log(y_proba_diag + <span class="syntax-number">1e-15</span>) + 
                                      (<span class="syntax-number">1</span> - y_test_class) * np.log(<span class="syntax-number">1</span> - y_proba_diag + <span class="syntax-number">1e-15</span>)))
residuos_deviance *= np.sign(y_test_class - y_proba_diag)

<span class="syntax-comment"># Teste de calibra√ß√£o (Hosmer-Lemeshow)</span>
<span class="syntax-keyword">def</span> <span class="syntax-function">hosmer_lemeshow_test</span>(y_true, y_prob, n_bins=<span class="syntax-number">10</span>):
    <span class="syntax-string">"""Implementa√ß√£o simplificada do teste Hosmer-Lemeshow"""</span>
    <span class="syntax-comment"># Dividir em bins baseado nas probabilidades preditas</span>
    bin_boundaries = np.percentile(y_prob, np.linspace(<span class="syntax-number">0</span>, <span class="syntax-number">100</span>, n_bins + <span class="syntax-number">1</span>))
    bin_boundaries[<span class="syntax-number">0</span>] -= <span class="syntax-number">0.001</span>  <span class="syntax-comment"># Incluir valores m√≠nimos</span>
    bin_boundaries[-<span class="syntax-number">1</span>] += <span class="syntax-number">0.001</span>  <span class="syntax-comment"># Incluir valores m√°ximos</span>
    
    chi2_stat = <span class="syntax-number">0</span>
    
    for i in <span class="syntax-function">range</span>(n_bins):
        <span class="syntax-comment"># M√°scara para este bin</span>
        mask = (y_prob >= bin_boundaries[i]) & (y_prob < bin_boundaries[i + <span class="syntax-number">1</span>])
        
        if np.sum(mask) > <span class="syntax-number">0</span>:
            <span class="syntax-comment"># Observado vs Esperado</span>
            observed = np.sum(y_true[mask])
            expected = np.sum(y_prob[mask])
            n_bin = np.sum(mask)
            
            if expected > <span class="syntax-number">0</span> and (n_bin - expected) > <span class="syntax-number">0</span>:
                chi2_stat += ((observed - expected) ** <span class="syntax-number">2</span>) / expected
                chi2_stat += (((n_bin - observed) - (n_bin - expected)) ** <span class="syntax-number">2</span>) / (n_bin - expected)
    
    <span class="syntax-comment"># p-value (graus de liberdade = n_bins - 2)</span>
    p_value = <span class="syntax-number">1</span> - stats.chi2.cdf(chi2_stat, n_bins - <span class="syntax-number">2</span>)
    
    return chi2_stat, p_value

hl_stat, hl_p = hosmer_lemeshow_test(y_test_class, y_proba_diag)
print(<span class="syntax-string">f"üìä Teste Hosmer-Lemeshow: œá¬≤ = {hl_stat:.4f}, p-value = {hl_p:.4f}"</span>)
print(<span class="syntax-string">f"   {'‚úÖ' if hl_p > 0.05 else '‚ùå'} Calibra√ß√£o (Œ± = 0.05)"</span>)

<span class="syntax-comment"># 6. CROSS-VALIDATION DETALHADA</span>
print(<span class="syntax-string">f"\nüîç VALIDA√á√ÉO CRUZADA DETALHADA"</span>)
print(<span class="syntax-string">"="*50</span>)

<span class="syntax-keyword">from</span> sklearn.model_selection <span class="syntax-keyword">import</span> KFold, StratifiedKFold

<span class="syntax-comment"># CV para Regress√£o</span>
kfold = KFold(n_splits=<span class="syntax-number">5</span>, shuffle=<span class="syntax-keyword">True</span>, random_state=<span class="syntax-number">42</span>)
cv_scores_reg = cross_val_score(modelo_multiplo, X_train_mult_scaled, y_train_mult, cv=kfold, scoring=<span class="syntax-string">'r2'</span>)

print(<span class="syntax-string">f"üìä Regress√£o Linear (R¬≤ CV):"</span>)
print(<span class="syntax-string">f"   M√©dia: {cv_scores_reg.mean():.3f} ¬± {cv_scores_reg.std():.3f}"</span>)
print(<span class="syntax-string">f"   Min: {cv_scores_reg.min():.3f}, Max: {cv_scores_reg.max():.3f}"</span>)

<span class="syntax-comment"># CV para Classifica√ß√£o</span>
skfold = StratifiedKFold(n_splits=<span class="syntax-number">5</span>, shuffle=<span class="syntax-keyword">True</span>, random_state=<span class="syntax-number">42</span>)
cv_scores_class = cross_val_score(logistic_simple, X_train_class_scaled, y_train_class, cv=skfold, scoring=<span class="syntax-string">'roc_auc'</span>)

print(<span class="syntax-string">f"üìä Regress√£o Log√≠stica (ROC-AUC CV):"</span>)
print(<span class="syntax-string">f"   M√©dia: {cv_scores_class.mean():.3f} ¬± {cv_scores_class.std():.3f}"</span>)
print(<span class="syntax-string">f"   Min: {cv_scores_class.min():.3f}, Max: {cv_scores_class.max():.3f}"</span>)

<span class="syntax-comment"># VISUALIZA√á√ïES DE DIAGN√ìSTICO</span>
fig, axes = plt.subplots(<span class="syntax-number">3</span>, <span class="syntax-number">3</span>, figsize=(<span class="syntax-number">18</span>, <span class="syntax-number">16</span>))
fig.suptitle(<span class="syntax-string">'Diagn√≥sticos Completos de Modelos de Regress√£o'</span>, fontsize=<span class="syntax-number">16</span>)

<span class="syntax-comment"># 1. Q-Q plot dos res√≠duos (regress√£o)</span>
stats.probplot(residuos_diag, dist=<span class="syntax-string">"norm"</span>, plot=axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>])
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].set_title(<span class="syntax-string">'Q-Q Plot - Res√≠duos Regress√£o'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">0</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 2. Res√≠duos vs Fitted</span>
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].scatter(y_pred_diag, residuos_diag, alpha=<span class="syntax-number">0.6</span>, color=cores_regressao[<span class="syntax-string">'residuos'</span>])
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].axhline(y=<span class="syntax-number">0</span>, color=<span class="syntax-string">'red'</span>, linestyle=<span class="syntax-string">'--'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_xlabel(<span class="syntax-string">'Valores Fitted'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_ylabel(<span class="syntax-string">'Res√≠duos'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].set_title(<span class="syntax-string">'Res√≠duos vs Fitted Values'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">1</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 3. Scale-Location plot</span>
sqrt_abs_residuos = np.sqrt(np.abs(residuos_std))
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].scatter(y_pred_diag, sqrt_abs_residuos, alpha=<span class="syntax-number">0.6</span>, color=cores_regressao[<span class="syntax-string">'ridge'</span>])
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].set_xlabel(<span class="syntax-string">'Valores Fitted'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].set_ylabel(<span class="syntax-string">'‚àö|Res√≠duos Padronizados|'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].set_title(<span class="syntax-string">'Scale-Location Plot'</span>)
axes[<span class="syntax-number">0</span>, <span class="syntax-number">2</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 4. Histogram dos res√≠duos</span>
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].hist(residuos_diag, bins=<span class="syntax-number">30</span>, color=cores_regressao[<span class="syntax-string">'linear'</span>], alpha=<span class="syntax-number">0.7</span>, 
                     density=<span class="syntax-keyword">True</span>, edgecolor=<span class="syntax-string">'black'</span>)

<span class="syntax-comment"># Overlay normal distribution</span>
x_norm = np.linspace(residuos_diag.min(), residuos_diag.max(), <span class="syntax-number">100</span>)
y_norm = stats.norm.pdf(x_norm, residuos_diag.mean(), residuos_diag.std())
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].plot(x_norm, y_norm, <span class="syntax-string">'r-'</span>, linewidth=<span class="syntax-number">2</span>, label=<span class="syntax-string">'Normal'</span>)

axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_xlabel(<span class="syntax-string">'Res√≠duos'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_ylabel(<span class="syntax-string">'Densidade'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].set_title(<span class="syntax-string">'Distribui√ß√£o dos Res√≠duos'</span>)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].legend()
axes[<span class="syntax-number">1</span>, <span class="syntax-number">0</span>].grid(<span class="syntax-keyword">True</span>, alpha=<span class="syntax-number">0.3</span>)

<span class="syntax-comment"># 5. Leverage vs Residuals (Cook's Distance)</span>
<span class="syntax-comment"># Simplificado - usar influ√™ncia dos pontos</span>
leverage = np.diagonal(X_test_mult_scaled @ np.linalg.pinv(X_train_mult_scaled.T @ X_train_mult_scaled) @ X_test_mult_scaled.T)
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].scatter(leverage, residuos_std, alpha=<span class="syntax-number">0.6</span>, color=cores_regressao[<span class="syntax-string">'elastic'</span>])
axes[<span class="syntax-number">1</span>, <span class="syntax-number">1</span>].axhline(y=<span class="syntax-number">0</span>, color=<span class="syntax-string">'red'
