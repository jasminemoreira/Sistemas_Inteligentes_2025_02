<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Redes Neurais Artificiais - Sistemas Inteligentes</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Display', system-ui, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
            color: #1a1a1a;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(20px);
            border-radius: 24px;
            padding: 40px;
            box-shadow: 0 20px 40px rgba(102, 126, 234, 0.3);
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
        }

        .badge {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 12px 24px;
            border-radius: 25px;
            font-size: 14px;
            font-weight: 600;
            display: inline-block;
            margin-bottom: 20px;
        }

        .title {
            font-size: 2.8rem;
            font-weight: 700;
            color: #667eea;
            margin-bottom: 16px;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .subtitle {
            font-size: 1.2rem;
            color: #666;
            margin-bottom: 30px;
        }

        .section {
            background: rgba(255, 255, 255, 0.8);
            border-radius: 16px;
            padding: 30px;
            margin-bottom: 30px;
            border-left: 5px solid #667eea;
        }

        .section h2 {
            color: #667eea;
            font-size: 1.8rem;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 12px;
        }

        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .card {
            background: rgba(255, 255, 255, 0.9);
            border-radius: 12px;
            padding: 24px;
            border: 1px solid rgba(102, 126, 234, 0.2);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .card:hover { 
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(102, 126, 234, 0.2);
        }

        .card h3 {
            color: #667eea;
            font-size: 1.3rem;
            margin-bottom: 12px;
        }

        .highlight-box {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 30px;
            border-radius: 16px;
            margin: 25px 0;
        }

        .highlight-box h3 {
            color: white;
            margin-bottom: 15px;
            font-size: 1.5rem;
        }

        .concept-box {
            background: rgba(118, 75, 162, 0.1);
            border: 2px solid rgba(118, 75, 162, 0.3);
            border-radius: 12px;
            padding: 20px;
            margin: 20px 0;
        }

        .concept-box h4 {
            color: #764ba2;
            margin-bottom: 10px;
        }

        .success-box {
            background: rgba(40, 167, 69, 0.1);
            border: 2px solid rgba(40, 167, 69, 0.3);
            border-radius: 12px;
            padding: 20px;
            margin: 20px 0;
            border-left: 5px solid #28a745;
        }

        .warning-box {
            background: rgba(255, 193, 7, 0.1);
            border: 2px solid rgba(255, 193, 7, 0.3);
            border-radius: 12px;
            padding: 20px;
            margin: 20px 0;
            border-left: 5px solid #ffc107;
        }

        .interactive-box {
            background: linear-gradient(135deg, #FF6B6B, #ee5a52);
            color: white;
            border-radius: 16px;
            padding: 25px;
            margin: 25px 0;
        }

        .interactive-box h3 {
            color: white;
            margin-bottom: 15px;
        }

        .interactive-link {
            display: block;
            background: rgba(255, 255, 255, 0.2);
            padding: 15px 20px;
            margin: 10px 0;
            border-radius: 10px;
            color: white;
            text-decoration: none;
            transition: all 0.3s ease;
            border: 2px solid rgba(255, 255, 255, 0.3);
        }

        .interactive-link:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateX(5px);
            border-color: white;
        }

        .interactive-link strong {
            display: block;
            font-size: 1.1rem;
            margin-bottom: 5px;
        }

        .code-block {
            background: #1e1e1e;
            color: #e8e8e8;
            padding: 20px;
            border-radius: 12px;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            overflow-x: auto;
            margin: 15px 0;
            border-left: 4px solid #667eea;
        }

        .code-header {
            background: #2d2d2d;
            color: #fff;
            padding: 8px 16px;
            margin: -20px -20px 12px -20px;
            border-radius: 12px 12px 0 0;
            font-size: 12px;
            font-weight: 600;
        }

        .step-indicator {
            background: #667eea;
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 700;
            font-size: 18px;
        }

        .neuron-diagram {
            text-align: center;
            margin: 30px 0;
        }

        .neuron-diagram img {
            max-width: 100%;
            height: auto;
            border-radius: 12px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }

        .formula {
            background: rgba(102, 126, 234, 0.1);
            border-left: 4px solid #667eea;
            padding: 15px 20px;
            margin: 15px 0;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            font-size: 16px;
        }

        .activation-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }

        .activation-card {
            background: linear-gradient(135deg, #4CAF50, #45a049);
            color: white;
            border-radius: 10px;
            padding: 15px;
            text-align: center;
        }

        .activation-card h4 {
            color: white;
            margin-bottom: 8px;
        }

        @media (max-width: 768px) {
            .container { padding: 20px; margin: 10px; }
            .title { font-size: 2.2rem; }
            .grid { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="badge">üß† Unidade IV - Redes Neurais Artificiais</div>
            <h1 class="title">Redes Neurais Artificiais</h1>
            <p class="subtitle">Fundamentos, Arquiteturas e Aplica√ß√µes na Engenharia de Produ√ß√£o</p>
        </div>

        <div class="highlight-box">
            <h3>üéØ Por que Redes Neurais?</h3>
            <p>Redes neurais artificiais s√£o a base da revolu√ß√£o atual em IA. Inspiradas no funcionamento do c√©rebro humano, elas conseguem <strong>aprender padr√µes complexos</strong> a partir de dados, tornando-se essenciais para tarefas como reconhecimento de padr√µes, previs√£o, classifica√ß√£o e otimiza√ß√£o em ambientes industriais.</p>
        </div>

        <!-- Parte 1: Fundamentos -->
        <div class="section">
            <h2><span class="step-indicator">1</span>O que s√£o Redes Neurais Artificiais?</h2>
            <p>Uma rede neural artificial (RNA) √© um modelo computacional inspirado na estrutura e funcionamento dos neur√¥nios biol√≥gicos do c√©rebro humano. Ela √© composta por unidades de processamento interconectadas (neur√¥nios artificiais) que trabalham em conjunto para resolver problemas complexos.</p>
            
            <div class="concept-box">
                <h4>üß¨ Analogia Biol√≥gica vs. Artificial</h4>
                <p><strong>Neur√¥nio Biol√≥gico:</strong><br>
                ‚Ä¢ Dendritos: Recebem sinais de entrada<br>
                ‚Ä¢ N√∫cleo: Processa informa√ß√µes<br>
                ‚Ä¢ Ax√¥nio: Transmite sinal de sa√≠da<br>
                ‚Ä¢ Sinapses: Conex√µes com outros neur√¥nios<br><br>
                
                <strong>Neur√¥nio Artificial:</strong><br>
                ‚Ä¢ Entradas (inputs): Valores num√©ricos ponderados<br>
                ‚Ä¢ Fun√ß√£o de soma: Agrega todas as entradas<br>
                ‚Ä¢ Fun√ß√£o de ativa√ß√£o: Processa e decide sa√≠da<br>
                ‚Ä¢ Pesos sin√°pticos: For√ßa das conex√µes</p>
            </div>

            <div class="grid">
                <div class="card">
                    <h3>üî¢ Componentes B√°sicos</h3>
                    <p><strong>Neur√¥nios:</strong> Unidades de processamento<br>
                    <strong>Pesos (Weights):</strong> For√ßa das conex√µes<br>
                    <strong>Bias:</strong> Ajuste fino da ativa√ß√£o<br>
                    <strong>Fun√ß√£o de Ativa√ß√£o:</strong> Transforma a soma ponderada</p>
                </div>
                <div class="card">
                    <h3>üèóÔ∏è Arquitetura</h3>
                    <p><strong>Camada de Entrada:</strong> Recebe dados<br>
                    <strong>Camadas Ocultas:</strong> Processamento intermedi√°rio<br>
                    <strong>Camada de Sa√≠da:</strong> Resultado final<br>
                    <strong>Conex√µes:</strong> Ligam neur√¥nios entre camadas</p>
                </div>
                <div class="card">
                    <h3>üìö Aprendizado</h3>
                    <p><strong>Supervisionado:</strong> Com dados rotulados<br>
                    <strong>N√£o Supervisionado:</strong> Sem r√≥tulos<br>
                    <strong>Backpropagation:</strong> Ajuste de pesos<br>
                    <strong>Gradient Descent:</strong> Otimiza√ß√£o</p>
                </div>
            </div>
        </div>

        <!-- Parte 2: Matem√°tica do Neur√¥nio -->
        <div class="section">
            <h2><span class="step-indicator">2</span>Matem√°tica do Neur√¥nio Artificial</h2>
            <p>Entender a matem√°tica por tr√°s de um neur√¥nio artificial √© fundamental para compreender como a rede aprende e faz previs√µes.</p>

            <div class="concept-box">
                <h4>üéì Equa√ß√£o do Neur√¥nio</h4>
                <p>Um neur√¥nio artificial realiza duas opera√ß√µes principais:</p>
                
                <div class="formula">
                    <strong>1. Soma Ponderada:</strong><br>
                    z = Œ£(w·µ¢ √ó x·µ¢) + b<br>
                    z = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + ... + w‚Çôx‚Çô + b
                </div>
                
                <div class="formula">
                    <strong>2. Fun√ß√£o de Ativa√ß√£o:</strong><br>
                    y = œÜ(z)
                </div>
                
                <p style="margin-top: 15px;">
                <strong>Onde:</strong><br>
                ‚Ä¢ x·µ¢ = valores de entrada<br>
                ‚Ä¢ w·µ¢ = pesos sin√°pticos<br>
                ‚Ä¢ b = bias (vi√©s)<br>
                ‚Ä¢ z = soma ponderada<br>
                ‚Ä¢ œÜ = fun√ß√£o de ativa√ß√£o<br>
                ‚Ä¢ y = sa√≠da do neur√¥nio</p>
            </div>

            <div class="warning-box">
                <h4>üîç Exemplo Num√©rico</h4>
                <p>Considere um neur√¥nio com 3 entradas:</p>
                <div class="formula">
                    Entradas: x‚ÇÅ = 2, x‚ÇÇ = 3, x‚ÇÉ = 1<br>
                    Pesos: w‚ÇÅ = 0.5, w‚ÇÇ = -0.3, w‚ÇÉ = 0.8<br>
                    Bias: b = 0.1<br><br>
                    
                    z = (0.5 √ó 2) + (-0.3 √ó 3) + (0.8 √ó 1) + 0.1<br>
                    z = 1.0 - 0.9 + 0.8 + 0.1 = 1.0<br><br>
                    
                    Se usar ReLU: y = max(0, z) = max(0, 1.0) = 1.0<br>
                    Se usar Sigmoid: y = 1/(1 + e‚Åª¬π¬∑‚Å∞) ‚âà 0.731
                </div>
            </div>
        </div>

        <!-- Parte 3: Fun√ß√µes de Ativa√ß√£o -->
        <div class="section">
            <h2><span class="step-indicator">3</span>Fun√ß√µes de Ativa√ß√£o</h2>
            <p>As fun√ß√µes de ativa√ß√£o introduzem n√£o-linearidade na rede, permitindo que ela aprenda padr√µes complexos. Sem elas, a rede seria apenas uma combina√ß√£o linear, incapaz de resolver problemas complexos.</p>

            <div class="activation-grid">
                <div class="activation-card">
                    <h4>üîπ Sigmoid</h4>
                    <div class="formula" style="background: rgba(255,255,255,0.2); border-left: none;">
                        œÉ(x) = 1 / (1 + e‚ÅªÀ£)
                    </div>
                    <p>Sa√≠da: [0, 1]<br>Uso: Classifica√ß√£o bin√°ria</p>
                </div>
                <div class="activation-card" style="background: linear-gradient(135deg, #2196F3, #1976D2);">
                    <h4>üîπ Tanh</h4>
                    <div class="formula" style="background: rgba(255,255,255,0.2); border-left: none;">
                        tanh(x) = (eÀ£ - e‚ÅªÀ£) / (eÀ£ + e‚ÅªÀ£)
                    </div>
                    <p>Sa√≠da: [-1, 1]<br>Uso: Redes recorrentes</p>
                </div>
                <div class="activation-card" style="background: linear-gradient(135deg, #FF9800, #F57C00);">
                    <h4>üîπ ReLU</h4>
                    <div class="formula" style="background: rgba(255,255,255,0.2); border-left: none;">
                        ReLU(x) = max(0, x)
                    </div>
                    <p>Sa√≠da: [0, ‚àû)<br>Uso: Camadas ocultas (padr√£o)</p>
                </div>
                <div class="activation-card" style="background: linear-gradient(135deg, #9C27B0, #7B1FA2);">
                    <h4>üîπ Leaky ReLU</h4>
                    <div class="formula" style="background: rgba(255,255,255,0.2); border-left: none;">
                        LReLU(x) = max(0.01x, x)
                    </div>
                    <p>Sa√≠da: (-‚àû, ‚àû)<br>Uso: Evita neur√¥nios "mortos"</p>
                </div>
                <div class="activation-card" style="background: linear-gradient(135deg, #F44336, #D32F2F);">
                    <h4>üîπ Softmax</h4>
                    <div class="formula" style="background: rgba(255,255,255,0.2); border-left: none;">
                        œÉ(x·µ¢) = eÀ£‚Å± / Œ£eÀ£ ≤
                    </div>
                    <p>Sa√≠da: [0, 1] (soma = 1)<br>Uso: Multi-classifica√ß√£o</p>
                </div>
                <div class="activation-card" style="background: linear-gradient(135deg, #00BCD4, #0097A7);">
                    <h4>üîπ ELU</h4>
                    <div class="formula" style="background: rgba(255,255,255,0.2); border-left: none;">
                        ELU(x) = x se x>0<br>Œ±(eÀ£-1) se x‚â§0
                    </div>
                    <p>Sa√≠da: (-Œ±, ‚àû)<br>Uso: Converg√™ncia mais r√°pida</p>
                </div>
            </div>

            <div class="success-box">
                <h4>üí° Qual Fun√ß√£o Usar?</h4>
                <p><strong>ReLU:</strong> Primeira escolha para camadas ocultas (r√°pida e eficaz)<br>
                <strong>Sigmoid:</strong> Classifica√ß√£o bin√°ria na sa√≠da (probabilidades 0-1)<br>
                <strong>Softmax:</strong> Classifica√ß√£o multi-classe na sa√≠da<br>
                <strong>Tanh:</strong> Quando dados centralizados em zero s√£o importantes<br>
                <strong>Leaky ReLU/ELU:</strong> Quando ReLU causa "neur√¥nios mortos"</p>
            </div>
        </div>

        <!-- Parte 4: Ferramentas Interativas -->
        <div class="section">
            <h2><span class="step-indicator">4</span>Ferramentas Interativas de Visualiza√ß√£o</h2>
            <p>A melhor forma de entender redes neurais √© <strong>experimentando</strong>! Estas ferramentas permitem visualizar e manipular redes neurais em tempo real.</p>

            <div class="interactive-box">
                <h3>üéÆ Playgrounds e Visualizadores</h3>
                <p style="margin-bottom: 20px;">Clique nos links abaixo para explorar visualiza√ß√µes interativas de redes neurais:</p>

                <a href="https://wimbiscus.com/neural-network/" target="_blank" class="interactive-link">
                    <strong>üéØ A Neural Network Playground</strong>
                    Experimente com diferentes arquiteturas, datasets e hiperpar√¢metros. Visualize como a rede aprende em tempo real!
                </a>

                <a href="https://www.cs.ryerson.ca/~aharley/vis/fc/" target="_blank" class="interactive-link">
                    <strong>üî∑ 3D Fully-Connected Network Visualization</strong>
                    Visualiza√ß√£o 3D interativa de uma rede totalmente conectada processando d√≠gitos manuscritos (MNIST).
                </a>

                <a href="https://www.cs.ryerson.ca/~aharley/vis/conv/" target="_blank" class="interactive-link">
                    <strong>üî∂ 3D Convolutional Network Visualization</strong>
                    Veja como uma CNN processa imagens camada por camada, extraindo features progressivamente.
                </a>

                <a href="https://www.cs.ryerson.ca/~aharley/vis/harley_vis_isvc15.pdf" target="_blank" class="interactive-link">
                    <strong>üìä MNIST Playground - CNN</strong>
                    Desenhe d√≠gitos e veja como a rede neural convolucional reconhece em tempo real.
                </a>

                <a href="https://playground.tensorflow.org/" target="_blank" class="interactive-link">
                    <strong>üß™ TensorFlow Playground</strong>
                    Playground oficial do TensorFlow para experimentar com redes neurais simples.
                </a>
            </div>

            <div class="warning-box">
                <h4>üéì Como Usar os Playgrounds</h4>
                <p><strong>1. Comece Simples:</strong> Use datasets pequenos (c√≠rculos, XOR) primeiro<br>
                <strong>2. Varie Arquitetura:</strong> Adicione/remova neur√¥nios e camadas<br>
                <strong>3. Teste Ativa√ß√µes:</strong> Compare ReLU, Sigmoid, Tanh<br>
                <strong>4. Ajuste Learning Rate:</strong> Veja o impacto na converg√™ncia<br>
                <strong>5. Observe Overfitting:</strong> Use regulariza√ß√£o quando necess√°rio</p>
            </div>
        </div>

        <!-- Parte 5: Tipos de Redes -->
        <div class="section">
            <h2><span class="step-indicator">5</span>Tipos de Redes Neurais</h2>
            <p>Existem diferentes arquiteturas de redes neurais, cada uma otimizada para tipos espec√≠ficos de problemas.</p>

            <div class="grid">
                <div class="card">
                    <h3>üî∑ Feedforward (MLP)</h3>
                    <p><strong>Estrutura:</strong> Camadas totalmente conectadas<br>
                    <strong>Fluxo:</strong> Unidirecional (entrada ‚Üí sa√≠da)<br>
                    <strong>Uso:</strong> Classifica√ß√£o, regress√£o<br>
                    <strong>Exemplo:</strong> Previs√£o de demanda, detec√ß√£o de defeitos</p>
                </div>
                <div class="card">
                    <h3>üñºÔ∏è CNN (Convolucional)</h3>
                    <p><strong>Estrutura:</strong> Camadas convolucionais + pooling<br>
                    <strong>Especialidade:</strong> Processamento de imagens<br>
                    <strong>Uso:</strong> Vis√£o computacional<br>
                    <strong>Exemplo:</strong> Inspe√ß√£o visual de qualidade, OCR</p>
                </div>
                <div class="card">
                    <h3>üîÑ RNN (Recorrente)</h3>
                    <p><strong>Estrutura:</strong> Conex√µes recorrentes (mem√≥ria)<br>
                    <strong>Especialidade:</strong> Dados sequenciais<br>
                    <strong>Uso:</strong> S√©ries temporais, NLP<br>
                    <strong>Exemplo:</strong> Previs√£o de vendas, manuten√ß√£o preditiva</p>
                </div>
            </div>

            <div class="concept-box">
                <h4>üèóÔ∏è Deep Learning vs. Redes Rasas</h4>
                <p><strong>Redes Rasas (Shallow):</strong> 1-2 camadas ocultas<br>
                ‚Ä¢ Mais simples e r√°pidas de treinar<br>
                ‚Ä¢ Boas para problemas lineares ou pouco complexos<br>
                ‚Ä¢ Menos propensas a overfitting<br><br>

                <strong>Redes Profundas (Deep):</strong> 3+ camadas ocultas<br>
                ‚Ä¢ Aprendem representa√ß√µes hier√°rquicas<br>
                ‚Ä¢ Capazes de capturar padr√µes muito complexos<br>
                ‚Ä¢ Requerem mais dados e poder computacional<br>
                ‚Ä¢ Podem sofrer de overfitting e vanishing gradients</p>
            </div>
        </div>

        <!-- Parte 6: Treinamento -->
        <div class="section">
            <h2><span class="step-indicator">6</span>Treinamento de Redes Neurais</h2>
            <p>O processo de treinamento √© onde a "m√°gica" acontece: a rede ajusta seus pesos para minimizar erros.</p>

            <div class="concept-box">
                <h4>üìê Algoritmo de Backpropagation</h4>
                <p><strong>Fase Forward (Propaga√ß√£o para Frente):</strong><br>
                1. Dados entram pela camada de entrada<br>
                2. Cada neur√¥nio calcula sua soma ponderada<br>
                3. Aplica fun√ß√£o de ativa√ß√£o<br>
                4. Passa resultado para pr√≥xima camada<br>
                5. Sa√≠da final √© comparada com valor real<br><br>

                <strong>Fase Backward (Retropropaga√ß√£o):</strong><br>
                1. Calcula erro na sa√≠da (Loss Function)<br>
                2. Propaga erro de volta pelas camadas<br>
                3. Calcula gradiente para cada peso<br>
                4. Atualiza pesos usando Gradient Descent<br>
                5. Repete processo at√© converg√™ncia</p>
            </div>

            <div class="formula">
                <strong>Atualiza√ß√£o de Pesos (Gradient Descent):</strong><br><br>
                w_novo = w_antigo - Œ∑ √ó ‚àÇL/‚àÇw<br><br>
                Onde:<br>
                ‚Ä¢ Œ∑ (eta) = learning rate (taxa de aprendizado)<br>
                ‚Ä¢ ‚àÇL/‚àÇw = derivada parcial do erro em rela√ß√£o ao peso<br>
                ‚Ä¢ Valor t√≠pico de Œ∑: 0.001 a 0.1
            </div>

            <div class="grid">
                <div class="card">
                    <h3>üìä Fun√ß√µes de Loss</h3>
                    <p><strong>MSE:</strong> Mean Squared Error - Regress√£o<br>
                    <strong>Cross-Entropy:</strong> Classifica√ß√£o bin√°ria<br>
                    <strong>Categorical CE:</strong> Multi-classe<br>
                    <strong>MAE:</strong> Mean Absolute Error - Robusta a outliers</p>
                </div>
                <div class="card">
                    <h3>‚öôÔ∏è Otimizadores</h3>
                    <p><strong>SGD:</strong> Stochastic Gradient Descent<br>
                    <strong>Adam:</strong> Adaptive Moment Estimation (recomendado)<br>
                    <strong>RMSprop:</strong> Root Mean Square Propagation<br>
                    <strong>AdaGrad:</strong> Adaptive Gradient</p>
                </div>
                <div class="card">
                    <h3>üéØ Hiperpar√¢metros</h3>
                    <p><strong>Learning Rate:</strong> Velocidade de aprendizado<br>
                    <strong>Batch Size:</strong> Amostras por atualiza√ß√£o<br>
                    <strong>Epochs:</strong> Passadas completas pelo dataset<br>
                    <strong>Regulariza√ß√£o:</strong> L1, L2, Dropout</p>
                </div>
            </div>

            <div class="warning-box">
                <h4>‚ö†Ô∏è Problemas Comuns no Treinamento</h4>
                <p><strong>Overfitting:</strong> Rede "decora" dados de treino<br>
                <strong>Solu√ß√µes:</strong> Dropout, regulariza√ß√£o, mais dados, data augmentation<br><br>

                <strong>Underfitting:</strong> Rede muito simples para o problema<br>
                <strong>Solu√ß√µes:</strong> Aumentar camadas/neur√¥nios, treinar mais epochs<br><br>

                <strong>Vanishing Gradient:</strong> Gradientes muito pequenos em redes profundas<br>
                <strong>Solu√ß√µes:</strong> ReLU, batch normalization, skip connections<br><br>

                <strong>Exploding Gradient:</strong> Gradientes crescem exponencialmente<br>
                <strong>Solu√ß√µes:</strong> Gradient clipping, normaliza√ß√£o, learning rate menor</p>
            </div>
        </div>

        <!-- Parte 7: Implementa√ß√£o Pr√°tica -->
        <div class="section">
            <h2><span class="step-indicator">7</span>Implementa√ß√£o com Python e TensorFlow</h2>
            <p>Vamos implementar uma rede neural simples para classifica√ß√£o usando TensorFlow/Keras.</p>

            <div class="code-block">
                <div class="code-header">üêç Exemplo 1: Rede Neural B√°sica (MLP)</div>
<pre><code>import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 1. PREPARA√á√ÉO DOS DADOS
# Exemplo: Dataset de qualidade de produ√ß√£o
# Features: temperatura, press√£o, velocidade, umidade
# Target: produto defeituoso (0) ou ok (1)

# Gerar dados sint√©ticos para exemplo
np.random.seed(42)
n_samples = 1000

X = np.random.randn(n_samples, 4)  # 4 features
y = (X[:, 0] + X[:, 1] > 0).astype(int)  # regra simples

# Split treino/teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Normaliza√ß√£o
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 2. CONSTRU√á√ÉO DO MODELO
model = keras.Sequential([
    # Camada de entrada + primeira oculta
    keras.layers.Dense(16, activation='relu', input_shape=(4,)),
    keras.layers.Dropout(0.2),  # Previne overfitting
    
    # Segunda camada oculta
    keras.layers.Dense(8, activation='relu'),
    keras.layers.Dropout(0.2),
    
    # Camada de sa√≠da
    keras.layers.Dense(1, activation='sigmoid')  # Bin√°ria
])

# 3. COMPILA√á√ÉO
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Visualizar arquitetura
model.summary()

# 4. TREINAMENTO
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_split=0.2,
    verbose=1
)

# 5. AVALIA√á√ÉO
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'\nAcur√°cia no teste: {test_accuracy:.4f}')

# 6. PREDI√á√ÉO
predictions = model.predict(X_test[:5])
print('\nPrimeiras 5 predi√ß√µes:')
print(predictions.flatten())</code></pre>
            </div>

            <div class="code-block">
                <div class="code-header">üî• Exemplo 2: Rede para Classifica√ß√£o Multi-classe</div>
<pre><code># Problema: Classificar tipo de defeito (3 classes)
# Classes: 0=Sem defeito, 1=Risco, 2=Mancha

from tensorflow.keras.utils import to_categorical

# Dados com 3 classes
y_multi = np.random.randint(0, 3, size=n_samples)
y_train_cat = to_categorical(y_multi[:800], num_classes=3)
y_test_cat = to_categorical(y_multi[800:], num_classes=3)

# Modelo para multi-classe
model_multi = keras.Sequential([
    keras.layers.Dense(32, activation='relu', input_shape=(4,)),
    keras.layers.BatchNormalization(),  # Normaliza ativa√ß√µes
    keras.layers.Dropout(0.3),
    
    keras.layers.Dense(16, activation='relu'),
    keras.layers.BatchNormalization(),
    keras.layers.Dropout(0.3),
    
    # Sa√≠da com 3 neur√¥nios (uma classe por neur√¥nio)
    keras.layers.Dense(3, activation='softmax')  # Multi-classe
])

model_multi.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Early Stopping: Para quando n√£o melhorar
early_stop = keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

history = model_multi.fit(
    X_train, y_train_cat,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[early_stop],
    verbose=0
)

print(f'Melhor epoch: {early_stop.stopped_epoch - 10}')
print(f'Melhor loss: {min(history.history["val_loss"]):.4f}')</code></pre>
            </div>

            <div class="success-box">
                <h4>üí° Boas Pr√°ticas de Implementa√ß√£o</h4>
                <p><strong>1. Sempre normalize os dados:</strong> StandardScaler ou MinMaxScaler<br>
                <strong>2. Use validation split:</strong> 10-20% dos dados de treino<br>
                <strong>3. Implemente Early Stopping:</strong> Evita overfitting<br>
                <strong>4. Salve o melhor modelo:</strong> ModelCheckpoint callback<br>
                <strong>5. Visualize o treinamento:</strong> Plote loss e accuracy<br>
                <strong>6. Teste diferentes arquiteturas:</strong> Varie camadas e neur√¥nios<br>
                <strong>7. Use Dropout e BatchNorm:</strong> Melhoram generaliza√ß√£o</p>
            </div>
        </div>

        <!-- Parte 8: Aplica√ß√µes na Engenharia -->
        <div class="section">
            <h2><span class="step-indicator">8</span>Aplica√ß√µes na Engenharia de Produ√ß√£o</h2>
            <p>Redes neurais est√£o revolucionando a ind√∫stria 4.0 com aplica√ß√µes pr√°ticas que geram valor real.</p>

            <div class="grid">
                <div class="card">
                    <h3>üîç Inspe√ß√£o Visual de Qualidade</h3>
                    <p><strong>Problema:</strong> Detectar defeitos em produtos<br>
                    <strong>Solu√ß√£o:</strong> CNN treinada com imagens<br>
                    <strong>Resultado:</strong> 99%+ acur√°cia, 24/7<br>
                    <strong>Exemplo Real:</strong> Bosch usa CNNs para inspe√ß√£o de pe√ßas automotivas</p>
                </div>
                <div class="card">
                    <h3>‚öôÔ∏è Manuten√ß√£o Preditiva</h3>
                    <p><strong>Problema:</strong> Prever falhas em equipamentos<br>
                    <strong>Solu√ß√£o:</strong> RNN/LSTM com dados de sensores<br>
                    <strong>Resultado:</strong> -30% custos manuten√ß√£o<br>
                    <strong>Exemplo Real:</strong> GE Predix usa ML para turbinas</p>
                </div>
                <div class="card">
                    <h3>üìä Previs√£o de Demanda</h3>
                    <p><strong>Problema:</strong> Estimar vendas futuras<br>
                    <strong>Solu√ß√£o:</strong> RNN com s√©ries temporais<br>
                    <strong>Resultado:</strong> +25% acur√°cia vs. modelos cl√°ssicos<br>
                    <strong>Exemplo Real:</strong> Amazon usa DNNs para forecast</p>
                </div>
                <div class="card">
                    <h3>üéØ Otimiza√ß√£o de Processos</h3>
                    <p><strong>Problema:</strong> Ajustar par√¢metros de produ√ß√£o<br>
                    <strong>Solu√ß√£o:</strong> MLP para predi√ß√£o de qualidade<br>
                    <strong>Resultado:</strong> -15% defeitos<br>
                    <strong>Exemplo Real:</strong> Steel manufacturing optimization</p>
                </div>
            </div>

            <div class="code-block">
                <div class="code-header">üìà Exemplo 3: Manuten√ß√£o Preditiva com Dados de Sensores</div>
<pre><code># Dataset: Sensores de temperatura, vibra√ß√£o, press√£o
# Target: Falha nas pr√≥ximas 24h (0=N√£o, 1=Sim)

import pandas as pd
from tensorflow.keras.layers import LSTM, Dense

# Simular dados de s√©ries temporais
sequence_length = 24  # 24 horas de hist√≥rico
n_features = 3  # temp, vibra√ß√£o, press√£o

# Criar dados sequenciais
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length, :-1])  # Features
        y.append(data[i+seq_length, -1])     # Target
    return np.array(X), np.array(y)

# Gerar dados sint√©ticos
n_samples = 5000
data = np.random.randn(n_samples, n_features + 1)
data[:, -1] = (data[:, 0] > 2).astype(int)  # Regra simples

X_seq, y_seq = create_sequences(data, sequence_length)
split = int(0.8 * len(X_seq))
X_train, X_test = X_seq[:split], X_seq[split:]
y_train, y_test = y_seq[:split], y_seq[split:]

# Modelo LSTM para s√©ries temporais
model_lstm = keras.Sequential([
    LSTM(64, activation='relu', input_shape=(sequence_length, n_features),
         return_sequences=True),
    keras.layers.Dropout(0.2),
    
    LSTM(32, activation='relu'),
    keras.layers.Dropout(0.2),
    
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')
])

model_lstm.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]
)

history = model_lstm.fit(
    X_train, y_train,
    epochs=30,
    batch_size=64,
    validation_data=(X_test, y_test),
    verbose=0
)

# Avaliar com m√©tricas espec√≠ficas
from sklearn.metrics import classification_report, confusion_matrix

y_pred = (model_lstm.predict(X_test) > 0.5).astype(int)
print('\nRelat√≥rio de Classifica√ß√£o:')
print(classification_report(y_test, y_pred, 
                          target_names=['Normal', 'Falha']))

print('\nMatriz de Confus√£o:')
print(confusion_matrix(y_test, y_pred))</code></pre>
            </div>
        </div>

        <!-- Parte 9: Pr√≥ximos Passos -->
        <div class="section">
            <h2><span class="step-indicator">9</span>Checkpoint 4: Projeto Pr√°tico</h2>
            
            <div class="interactive-box">
                <h3>üéØ Desafio: Implementar Rede Neural para Problema Real</h3>
                <p><strong>Objetivo:</strong> Desenvolver uma rede neural para resolver um problema de engenharia de produ√ß√£o</p>
                
                <p style="margin-top: 15px;"><strong>Requisitos do Projeto:</strong></p>
                <ul style="margin-left: 20px; margin-top: 10px;">
                    <li>Escolher um problema real (inspe√ß√£o, previs√£o, classifica√ß√£o, otimiza√ß√£o)</li>
                    <li>Coletar ou gerar dataset apropriado (m√≠nimo 500 amostras)</li>
                    <li>Implementar e treinar rede neural (TensorFlow/Keras)</li>
                    <li>Avaliar performance com m√©tricas adequadas</li>
                    <li>Comparar com pelo menos um baseline (regress√£o log√≠stica, √°rvore de decis√£o)</li>
                    <li>Documentar arquitetura, hiperpar√¢metros e resultados</li>
                </ul>

                <p style="margin-top: 15px;"><strong>Entreg√°veis (28/10):</strong></p>
                <ul style="margin-left: 20px; margin-top: 10px;">
                    <li>Notebook Jupyter com c√≥digo completo e comentado</li>
                    <li>Relat√≥rio t√©cnico (3-5 p√°ginas) com metodologia e resultados</li>
                    <li>Apresenta√ß√£o (10 minutos) demonstrando o modelo funcionando</li>
                </ul>
            </div>

            <div class="warning-box">
                <h4>üìö Temas Sugeridos para o Projeto</h4>
                <p><strong>‚Ä¢ Classifica√ß√£o de Defeitos:</strong> Usar dataset Steel Plates ou similar<br>
                <strong>‚Ä¢ Previs√£o de Qualidade:</strong> Wine Quality ou Concrete Strength<br>
                <strong>‚Ä¢ Detec√ß√£o de Anomalias:</strong> NASA Bearing ou SECOM<br>
                <strong>‚Ä¢ Previs√£o de Demanda:</strong> Retail sales ou similar<br>
                <strong>‚Ä¢ Reconhecimento de Padr√µes:</strong> MNIST ou Fashion-MNIST<br>
                <strong>‚Ä¢ Manuten√ß√£o Preditiva:</strong> Simula√ß√£o com dados de sensores</p>
            </div>
        </div>

        <!-- Conclus√£o -->
        <div class="section">
            <h2><span class="step-indicator">10</span>Recursos Adicionais</h2>
            
            <div class="success-box">
                <h4>üìñ Material de Estudo Recomendado</h4>
                <p><strong>Livros:</strong><br>
                ‚Ä¢ "Deep Learning" - Ian Goodfellow (B√≠blia do DL)<br>
                ‚Ä¢ "Neural Networks and Deep Learning" - Michael Nielsen (online gr√°tis)<br>
                ‚Ä¢ "Hands-On Machine Learning" - Aur√©lien G√©ron<br><br>

                <strong>Cursos Online:</strong><br>
                ‚Ä¢ Fast.ai - Practical Deep Learning for Coders<br>
                ‚Ä¢ Coursera - Deep Learning Specialization (Andrew Ng)<br>
                ‚Ä¢ TensorFlow Official Tutorials<br><br>

                <strong>Datasets para Pr√°tica:</strong><br>
                ‚Ä¢ UCI Machine Learning Repository<br>
                ‚Ä¢ Kaggle Datasets<br>
                ‚Ä¢ TensorFlow Datasets<br>
                ‚Ä¢ OpenML</p>
            </div>

            <div class="highlight-box">
                <h3>üåü Conclus√£o</h3>
                <p>Redes Neurais Artificiais representam uma das tecnologias mais transformadoras da atualidade. Na engenharia de produ√ß√£o, elas permitem automatizar decis√µes complexas, otimizar processos e extrair insights valiosos de grandes volumes de dados. O dom√≠nio desta tecnologia √© essencial para o engenheiro moderno.</p>
                
                <p style="margin-top: 15px;"><strong>Pr√≥xima Aula (21/10):</strong> Aprofundamento em CNNs e aplica√ß√µes de vis√£o computacional para inspe√ß√£o de qualidade.</p>
            </div>
        </div>
    </div>
</body>
</html>